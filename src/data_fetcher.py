#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨æ•°æ®è·å–å™¨ - ä¿®å¤ç‰ˆæœ¬
ä¿®å¤äº†æ—¥æœŸèŒƒå›´ä¸æ­£ç¡®å’Œç¬¦å·éªŒè¯é—®é¢˜
æ·»åŠ äº†æ—¥æœŸèŒƒå›´å®Œæ•´æ€§æ£€æŸ¥
"""

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", message=".*urllib3 v2 only supports OpenSSL 1.1.1+.*")

import logging
import pandas as pd
import requests
import json
import re
import time
import random
import os
import sys
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Union, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

try:
    from src.config import get_data_fetcher_config, get_backtest_config, get_strategy_config
    CONFIG_AVAILABLE = True
except ImportError:
    CONFIG_AVAILABLE = False
    logging.warning("æ— æ³•å¯¼å…¥é…ç½®æ¨¡å—ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

logger = logging.getLogger('StockDataFetcher')
logger.setLevel(logging.INFO)

# é…ç½®æ—¥å¿—å¤„ç†å™¨
if not logger.handlers:
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

class DataFetchError(Exception):
    """æ•°æ®è·å–å¼‚å¸¸"""
    pass

class StockDataFetcher:
    """é«˜æ•ˆè‚¡ç¥¨æ•°æ®è·å–å™¨ - ä¿®å¤æ—¥æœŸèŒƒå›´å’Œç¬¦å·éªŒè¯é—®é¢˜"""
    
    def __init__(self, max_retries: int = None, timeout: int = None):
        """
        åˆå§‹åŒ–æ•°æ®è·å–å™¨
        :param max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        :param timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
        """
        # åŠ è½½é…ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼
        if CONFIG_AVAILABLE:
            try:
                config = get_data_fetcher_config()
                
                # è®¾ç½®å‚æ•°
                self.max_retries = max_retries or config.get('max_retries', 3)
                self.timeout = timeout or config.get('timeout', 10)
                self.type_safety = config.get('type_safety', True)
                self.data_sources = config.get('data_sources', ['tencent', 'sina'])
                self.cache_enabled = config.get('cache_enabled', True)
                self.cache_ttl = config.get('cache_ttl', 300)
                
                # è·å–Sinaé…ç½®
                sina_config = config.get('sina', {})
                self.sina_base_url = sina_config.get('base_url', "http://money.finance.sina.com.cn/quotes_service/api/json_v2.php/CN_MarketData.getKLineData")
                self.sina_params = sina_config.get('params', {})
                
                # è·å–Tencenté…ç½®
                tencent_config = config.get('tencent', {})
                self.tencent_enabled = tencent_config.get('enabled', True)
                self.tencent_weekly_url = tencent_config.get('weekly_url', "https://web.ifzq.gtimg.cn/appstock/app/fqkline/get")
                self.tencent_params = tencent_config.get('params', {})
                
                logger.info("é…ç½®æ¨¡å—åŠ è½½æˆåŠŸ")
                
            except Exception as e:
                logger.warning(f"é…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {str(e)}")
                self._set_default_config()
        else:
            self._set_default_config()
            logger.info("ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–")
        
        # åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
        self.cache = {}
        self.cache_timestamps = {}
        
        # åŠŸèƒ½å®Œæ•´æ€§æ£€æŸ¥
        self._feature_check()
        
        logger.info(f"æ•°æ®è·å–å™¨åˆå§‹åŒ–å®Œæˆ - æ”¯æŒåŠŸèƒ½: {self._get_feature_summary()}")
    
    def _set_default_config(self):
        """è®¾ç½®é»˜è®¤é…ç½®"""
        self.max_retries = 3
        self.timeout = 10
        self.type_safety = True
        self.data_sources = ['tencent', 'sina']
        self.cache_enabled = True
        self.cache_ttl = 300
        
        # Sinaé»˜è®¤é…ç½®
        self.sina_base_url = "http://money.finance.sina.com.cn/quotes_service/api/json_v2.php/CN_MarketData.getKLineData"
        self.sina_params = {
            'weekly': {'scale': 'week', 'ma': 'no', 'datalen': '500'},
            'daily': {'scale': '240', 'ma': 'no', 'datalen': '1000'},
            'minute': {'scale': '5', 'ma': 'no', 'datalen': '10000'}
        }
        
        # Tencenté»˜è®¤é…ç½®
        self.tencent_enabled = True
        self.tencent_weekly_url = "https://web.ifzq.gtimg.cn/appstock/app/fqkline/get"
        self.tencent_params = {
            'weekly': {'_var': 'kline_week', 'param': '{symbol},week,,,320,qfq'}
        }
    
    def _feature_check(self):
        """åŠŸèƒ½å®Œæ•´æ€§æ£€æŸ¥"""
        required_features = [
            'get_weekly_data', 'get_daily_data', 'get_realtime_data', 'get_minute_data',
            'health_check', 'cache_system', 'error_handling', 'data_validation'
        ]
        
        implemented_features = []
        
        # æ£€æŸ¥æ ¸å¿ƒæ•°æ®è·å–åŠŸèƒ½
        if hasattr(self, 'get_weekly_data') and callable(getattr(self, 'get_weekly_data')):
            implemented_features.append('get_weekly_data')
        
        if hasattr(self, 'get_daily_data') and callable(getattr(self, 'get_daily_data')):
            implemented_features.append('get_daily_data')
        
        if hasattr(self, 'get_realtime_data') and callable(getattr(self, 'get_realtime_data')):
            implemented_features.append('get_realtime_data')
        
        # æ£€æŸ¥åˆ†é’Ÿæ•°æ®åŠŸèƒ½
        if hasattr(self, 'get_minute_data') and callable(getattr(self, 'get_minute_data')):
            implemented_features.append('get_minute_data')
        
        # æ£€æŸ¥ç³»ç»ŸåŠŸèƒ½
        if hasattr(self, 'health_check') and callable(getattr(self, 'health_check')):
            implemented_features.append('health_check')
        
        if hasattr(self, '_get_from_cache') and hasattr(self, '_save_to_cache'):
            implemented_features.append('cache_system')
        
        if hasattr(self, '_request_with_retry'):
            implemented_features.append('error_handling')
        
        if hasattr(self, '_validate_symbol') and hasattr(self, '_validate_dates'):
            implemented_features.append('data_validation')
        
        # è®°å½•æ£€æŸ¥ç»“æœ
        missing_features = set(required_features) - set(implemented_features)
        
        if missing_features:
            logger.warning(f"ç¼ºå¤±åŠŸèƒ½: {missing_features}")
        else:
            logger.info("æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å·²å®Œæ•´å®ç°")
    
    def _get_feature_summary(self):
        """è·å–åŠŸèƒ½æ‘˜è¦"""
        features = []
        
        if 'tencent' in self.data_sources:
            features.append('è…¾è®¯æ•°æ®æº')
        if 'sina' in self.data_sources:
            features.append('æ–°æµªæ•°æ®æº')
        
        if self.cache_enabled:
            features.append('ç¼“å­˜ç³»ç»Ÿ')
        
        features.extend(['å‘¨çº¿æ•°æ®', 'æ—¥çº¿æ•°æ®', 'å®æ—¶æ•°æ®', 'åˆ†é’Ÿæ•°æ®', 'å¥åº·æ£€æŸ¥'])
        
        return ', '.join(features)
    
    def _convert_date_format(self, date_str: str) -> str:
        """
        æ—¥æœŸæ ¼å¼è½¬æ¢
        :param date_str: æ—¥æœŸå­—ç¬¦ä¸²
        :return: YYYYMMDDæ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²
        """
        if not date_str or not isinstance(date_str, str):
            return date_str
            
        # ç§»é™¤ç ´æŠ˜å·
        if '-' in date_str:
            date_str = date_str.replace('-', '')
        
        # å¦‚æœå·²ç»æ˜¯YYYYMMDDæ ¼å¼ï¼Œç›´æ¥è¿”å›
        if len(date_str) == 8 and date_str.isdigit():
            return date_str
            
        return date_str
    
    def _format_symbol(self, symbol: str) -> str:
        """
        æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç  - å¢å¼ºé”™è¯¯å¤„ç†
        :param symbol: è‚¡ç¥¨ä»£ç 
        :return: æ ‡å‡†åŒ–åçš„è‚¡ç¥¨ä»£ç ï¼ˆçº¯æ•°å­—ï¼‰
        """
        try:
            if not isinstance(symbol, str):
                symbol = str(symbol)
            
            # éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
            pattern = r'^([A-Za-z]{2})?(\d{6})(\.[A-Za-z]{2})?$'
            match = re.match(pattern, symbol)
            if not match:
                logger.warning(f"æ— æ•ˆè‚¡ç¥¨ä»£ç æ ¼å¼: {symbol}")
                return symbol  # è¿”å›åŸå§‹å€¼ï¼Œä¸ä¸­æ–­æµç¨‹
            
            # æå–æ•°å­—éƒ¨åˆ†
            digit_part = match.group(2)
            
            # è¿”å›çº¯æ•°å­—ä»£ç 
            return digit_part
            
        except Exception as e:
            logger.warning(f"è‚¡ç¥¨ä»£ç æ ¼å¼åŒ–å¤±è´¥: {symbol}, é”™è¯¯: {str(e)}")
            return symbol  # è¿”å›åŸå§‹å€¼ï¼Œä¸ä¸­æ–­æµç¨‹
    
    def _validate_symbol(self, symbol: str) -> str:
        """
        éªŒè¯å’Œæ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç  - é˜²å¾¡æ€§ä¿®å¤ï¼šå¢å¼ºç±»å‹å’Œé•¿åº¦æ£€æŸ¥
        :param symbol: è‚¡ç¥¨ä»£ç 
        :return: æ ‡å‡†åŒ–åçš„è‚¡ç¥¨ä»£ç ï¼ˆçº¯æ•°å­—ï¼‰
        """
        try:
            # ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ é˜²å¾¡æ€§ä¿®å¤ï¼šæ£€æŸ¥symbolç±»å‹ï¼Œé˜²æ­¢DataFrameç­‰æ— æ•ˆç±»å‹
            if symbol is None:
                raise DataFetchError("è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºNone")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºDataFrameæˆ–å…¶ä»–å¤æ‚å¯¹è±¡ï¼ˆé€šè¿‡å­—ç¬¦ä¸²è¡¨ç¤ºé•¿åº¦åˆ¤æ–­ï¼‰
            symbol_str = str(symbol)
            if len(symbol_str) > 100:  # æ­£å¸¸è‚¡ç¥¨ä»£ç ä¸ä¼šè¶…è¿‡20å­—ç¬¦ï¼Œ100ä»¥ä¸Šå¯èƒ½æ˜¯DataFrame
                logger.error(f"ç–‘ä¼¼DataFrameè¢«å½“ä½œè‚¡ç¥¨ä»£ç ä¼ é€’: {symbol_str[:100]}...")
                raise DataFetchError(f"æ— æ•ˆè‚¡ç¥¨ä»£ç ç±»å‹: ç–‘ä¼¼DataFrameå¯¹è±¡")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºPandas Seriesæˆ–DataFrameçš„å­—ç¬¦ä¸²è¡¨ç¤ºç‰¹å¾
            if any(marker in symbol_str for marker in ['DataFrame', 'Series', 'open', 'high', 'low', 'close', 'volume', 'date']):
                logger.error(f"æ£€æµ‹åˆ°DataFrameç‰¹å¾åœ¨è‚¡ç¥¨ä»£ç ä¸­: {symbol_str[:200]}")
                raise DataFetchError(f"æ— æ•ˆè‚¡ç¥¨ä»£ç : æ£€æµ‹åˆ°DataFrameç‰¹å¾")
            
            formatted_symbol = self._format_symbol(symbol)
            
            # éªŒè¯æ˜¯å¦ä¸º6ä½æ•°å­—
            if not re.match(r'^\d{6}$', formatted_symbol):
                raise DataFetchError(f"æ— æ•ˆè‚¡ç¥¨ä»£ç æ ¼å¼: {symbol} (æœŸæœ›6ä½æ•°å­—ï¼Œå¾—åˆ°: {formatted_symbol})")
            
            return formatted_symbol
            
        except DataFetchError:
            raise  # é‡æ–°æŠ›å‡ºå·²çŸ¥é”™è¯¯
        except Exception as e:
            logger.error(f"è‚¡ç¥¨ä»£ç éªŒè¯å¼‚å¸¸: {str(e)}")
            raise DataFetchError(f"è‚¡ç¥¨ä»£ç éªŒè¯å¤±è´¥: {symbol}")
    
    def _get_market_prefix(self, symbol: str) -> str:
        """
        è·å–å¸‚åœºå‰ç¼€ - å¢å¼ºé”™è¯¯å¤„ç†
        :param symbol: çº¯æ•°å­—è‚¡ç¥¨ä»£ç 
        :return: å¸‚åœºå‰ç¼€ ('sh' or 'sz')
        """
        try:
            if symbol.startswith("6") or symbol.startswith("5") or symbol.startswith("9"):
                return "sh"
            elif symbol.startswith("0") or symbol.startswith("3") or symbol.startswith("1"):
                return "sz"
            else:
                logger.warning(f"æ— æ³•è¯†åˆ«çš„è‚¡ç¥¨ä»£ç å‰ç¼€: {symbol}")
                return "sh"  # é»˜è®¤è¿”å›ä¸Šæµ·å¸‚åœº
                
        except Exception as e:
            logger.error(f"è·å–å¸‚åœºå‰ç¼€å¼‚å¸¸: {str(e)}")
            return "sh"  # é»˜è®¤è¿”å›ä¸Šæµ·å¸‚åœº
    
    def _validate_dates(self, start_date: Optional[str], end_date: Optional[str]) -> tuple:
        """
        éªŒè¯å’Œæ ‡å‡†åŒ–æ—¥æœŸèŒƒå›´ - å¢å¼ºé”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
        :param start_date: å¼€å§‹æ—¥æœŸ
        :param end_date: ç»“æŸæ—¥æœŸ
        :return: (start_dt, end_dt, original_start, original_end)
        """
        try:
            # ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ å¢å¼ºæ—¥å¿—ï¼šè®°å½•åŸå§‹æ—¥æœŸå‚æ•°
            logger.debug(f"æ—¥æœŸéªŒè¯è¾“å…¥ - start_date: {start_date}, end_date: {end_date}")
            
            # è®°å½•åŸå§‹å‚æ•°
            original_start = start_date
            original_end = end_date
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            if end_date:
                end_date = self._convert_date_format(end_date)
                logger.debug(f"è½¬æ¢åend_date: {end_date}")
            else:
                end_date = datetime.now().strftime("%Y%m%d")
                logger.debug(f"ä½¿ç”¨é»˜è®¤end_date: {end_date}")
                
            if start_date:
                start_date = self._convert_date_format(start_date)
                logger.debug(f"è½¬æ¢åstart_date: {start_date}")
            else:
                # ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç”¨æˆ·æä¾›çš„end_dateæ¥è®¡ç®—start_dateï¼Œè€Œä¸æ˜¯å½“å‰æ—¶é—´
                if end_date:
                    end_dt_temp = datetime.strptime(end_date, "%Y%m%d")
                    start_date = (end_dt_temp - timedelta(days=365)).strftime("%Y%m%d")
                else:
                    start_date = (datetime.now() - timedelta(days=365)).strftime("%Y%m%d")
                logger.debug(f"ä½¿ç”¨è®¡ç®—start_date: {start_date}")
            
            start_dt = datetime.strptime(start_date, "%Y%m%d")
            end_dt = datetime.strptime(end_date, "%Y%m%d")
            
            # ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ å¢å¼ºæ—¥å¿—ï¼šè®°å½•æœ€ç»ˆæ—¥æœŸèŒƒå›´
            date_range_days = (end_dt - start_dt).days
            logger.info(f"æ—¥æœŸèŒƒå›´éªŒè¯: {start_dt.strftime('%Y-%m-%d')} è‡³ {end_dt.strftime('%Y-%m-%d')} (å…±{date_range_days}å¤©)")
            
            if start_dt > end_dt:
                raise DataFetchError(f"å¼€å§‹æ—¥æœŸ {start_date} ä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ {end_date}")
                
            return start_dt, end_dt, original_start, original_end
            
        except ValueError as e:
            logger.error(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {str(e)}")
            raise DataFetchError("æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨YYYYMMDDæˆ–YYYY-MM-DDæ ¼å¼")
        except Exception as e:
            logger.error(f"æ—¥æœŸéªŒè¯å¼‚å¸¸: {str(e)}")
            raise DataFetchError(f"æ—¥æœŸéªŒè¯å¤±è´¥: {start_date} - {end_date}")
    
    def _get_cache_key(self, data_type: str, symbol: str, start_date: str, end_date: str) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”® - å¢å¼ºé”™è¯¯å¤„ç†
        :param data_type: æ•°æ®ç±»å‹
        :param symbol: è‚¡ç¥¨ä»£ç 
        :param start_date: å¼€å§‹æ—¥æœŸ
        :param end_date: ç»“æŸæ—¥æœŸ
        :return: ç¼“å­˜é”®
        """
        try:
            return f"{data_type}:{symbol}:{start_date}:{end_date}"
        except Exception as e:
            logger.error(f"ç”Ÿæˆç¼“å­˜é”®å¼‚å¸¸: {str(e)}")
            return f"error:{int(time.time())}"
    
    def _get_from_cache(self, cache_key: str) -> Optional[pd.DataFrame]:
        """
        ä»ç¼“å­˜è·å–æ•°æ® - å¢å¼ºé”™è¯¯å¤„ç†
        :param cache_key: ç¼“å­˜é”®
        :return: æ•°æ®DataFrameæˆ–None
        """
        try:
            if not self.cache_enabled:
                return None
            
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
            if cache_key in self.cache:
                if cache_key in self.cache_timestamps:
                    timestamp = self.cache_timestamps[cache_key]
                    if time.time() - timestamp < self.cache_ttl:
                        return self.cache[cache_key].copy()
                    else:
                        # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                        del self.cache[cache_key]
                        del self.cache_timestamps[cache_key]
            
            return None
            
        except Exception as e:
            logger.error(f"ä»ç¼“å­˜è·å–æ•°æ®å¼‚å¸¸: {str(e)}")
            return None
    
    def _save_to_cache(self, cache_key: str, data: pd.DataFrame):
        """
        ä¿å­˜æ•°æ®åˆ°ç¼“å­˜ - å¢å¼ºé”™è¯¯å¤„ç†
        :param cache_key: ç¼“å­˜é”®
        :param data: æ•°æ®DataFrame
        """
        try:
            if self.cache_enabled:
                self.cache[cache_key] = data.copy()
                self.cache_timestamps[cache_key] = time.time()
        except Exception as e:
            logger.error(f"ä¿å­˜æ•°æ®åˆ°ç¼“å­˜å¼‚å¸¸: {str(e)}")
    
    def _request_with_retry(self, request_func, *args, **kwargs):
        """
        å¸¦é‡è¯•çš„è¯·æ±‚åŒ…è£…å™¨ - å¢å¼ºé”™è¯¯å¤„ç†
        :param request_func: è¯·æ±‚å‡½æ•°
        :return: è¯·æ±‚ç»“æœ
        """
        for attempt in range(1, self.max_retries + 1):
            try:
                if attempt > 1:
                    time.sleep(random.uniform(0.5, 2.0))
                
                result = request_func(*args, **kwargs)
                if result is not None:
                    return result
                    
            except Exception as e:
                if attempt == self.max_retries:
                    logger.error(f"æ‰€æœ‰é‡è¯•å°è¯•å¤±è´¥: {str(e)}")
                    return None
                else:
                    logger.warning(f"å°è¯• {attempt} å¤±è´¥: {str(e)}")
        
        return None
    
    def _safe_dataframe_operation(self, df: pd.DataFrame, operation: str, **kwargs) -> pd.DataFrame:
        """
        å®‰å…¨çš„DataFrameæ“ä½œ - æ–°å¢ï¼šå¢å¼ºé”™è¯¯å¤„ç†
        :param df: DataFrame
        :param operation: æ“ä½œç±»å‹ ('rename', 'convert_dtypes', 'add_column')
        :return: å¤„ç†åçš„DataFrameæˆ–ç©ºDataFrame
        """
        try:
            if df is None or df.empty:
                return pd.DataFrame()
            
            if operation == 'rename':
                column_map = kwargs.get('column_map', {})
                return df.rename(columns=column_map)
                
            elif operation == 'convert_dtypes':
                date_col = kwargs.get('date_col', 'date')
                numeric_cols = kwargs.get('numeric_cols', [])
                
                if date_col in df.columns:
                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                
                for col in numeric_cols:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                
                return df
                
            elif operation == 'add_column':
                column_name = kwargs.get('column_name')
                column_value = kwargs.get('column_value')
                
                if column_name:
                    df[column_name] = column_value
                
                return df
                
            else:
                return df
                
        except Exception as e:
            logger.warning(f"DataFrameæ“ä½œå¤±è´¥: {operation}, é”™è¯¯: {str(e)}")
            return pd.DataFrame()
    
    def _check_date_range_completeness(self, df: pd.DataFrame, start_dt: datetime, end_dt: datetime, symbol: str, data_type: str):
        """
        æ£€æŸ¥æ—¥æœŸèŒƒå›´å®Œæ•´æ€§ - æ–°å¢ï¼šç¡®ä¿å®é™…æ•°æ®èŒƒå›´è¦†ç›–è¯·æ±‚èŒƒå›´
        :param df: æ•°æ®DataFrame
        :param start_dt: è¯·æ±‚å¼€å§‹æ—¥æœŸ
        :param end_dt: è¯·æ±‚ç»“æŸæ—¥æœŸ
        :param symbol: è‚¡ç¥¨ä»£ç 
        :param data_type: æ•°æ®ç±»å‹
        """
        if df.empty or 'date' not in df.columns:
            return
            
        # è·å–å®é™…æ•°æ®æ—¥æœŸèŒƒå›´
        actual_start = df['date'].min()
        actual_end = df['date'].max()
        
        # æ£€æŸ¥æ—¥æœŸèŒƒå›´å®Œæ•´æ€§
        if actual_start > start_dt or actual_end < end_dt:
            logger.warning(
                f"æ•°æ®æ—¥æœŸèŒƒå›´ä¸å®Œæ•´: {symbol} {data_type}\n"
                f"è¯·æ±‚èŒƒå›´: {start_dt.strftime('%Y-%m-%d')} è‡³ {end_dt.strftime('%Y-%m-%d')}\n"
                f"å®é™…èŒƒå›´: {actual_start.strftime('%Y-%m-%d')} è‡³ {actual_end.strftime('%Y-%m-%d')}\n"
                f"ç¼ºå¤±æ•°æ®: {self._get_missing_date_range(start_dt, end_dt, actual_start, actual_end)}"
            )
    
    def _get_missing_date_range(self, start_dt: datetime, end_dt: datetime, 
                               actual_start: datetime, actual_end: datetime) -> str:
        """
        è·å–ç¼ºå¤±çš„æ—¥æœŸèŒƒå›´æè¿°
        """
        missing_parts = []
        
        if actual_start > start_dt:
            missing_parts.append(f"å¼€å§‹éƒ¨åˆ†: {start_dt.strftime('%Y-%m-%d')} è‡³ {actual_start.strftime('%Y-%m-%d')}")
        
        if actual_end < end_dt:
            missing_parts.append(f"ç»“æŸéƒ¨åˆ†: {actual_end.strftime('%Y-%m-%d')} è‡³ {end_dt.strftime('%Y-%m-%d')}")
        
        return "; ".join(missing_parts) if missing_parts else "æ— ç¼ºå¤±æ•°æ®"
    
    def clean_symbol_format(self, symbol: str) -> str:
        """
        æ¸…æ´—è‚¡ç¥¨ä»£ç æ ¼å¼ - ç§»é™¤å¸‚åœºå‰ç¼€
        :param symbol: è‚¡ç¥¨ä»£ç 
        :return: çº¯æ•°å­—è‚¡ç¥¨ä»£ç 
        """
        try:
            if not isinstance(symbol, str):
                symbol = str(symbol)
            
            # ç§»é™¤å¸‚åœºå‰ç¼€
            if symbol.startswith(('sh', 'sz')):
                return symbol[2:]  # ç§»é™¤å‰2å­—ç¬¦
            return symbol
            
        except Exception as e:
            logger.warning(f"è‚¡ç¥¨ä»£ç æ¸…æ´—å¤±è´¥: {symbol}, é”™è¯¯: {str(e)}")
            return symbol
    
    def get_weekly_data(self, symbol: str, start_date: Optional[str] = None, 
                        end_date: Optional[str] = None) -> pd.DataFrame:
        """
        è·å–å‘¨çº¿æ•°æ® - å¢å¼ºé”™è¯¯å¤„ç†å’Œæ—¥æœŸæ—¥å¿—
        :param symbol: è‚¡ç¥¨ä»£ç 
        :param start_date: å¼€å§‹æ—¥æœŸ
        :param end_date: ç»“æŸæ—¥æœŸ
        :return: å‘¨çº¿æ•°æ®DataFrame
        """
        try:
            # ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ å¢å¼ºæ—¥å¿—ï¼šè®°å½•æ–¹æ³•è°ƒç”¨å‚æ•°
            logger.info(f"è·å–å‘¨çº¿æ•°æ® - ç¬¦å·: {symbol}, å¼€å§‹: {start_date}, ç»“æŸ: {end_date}")
            
            # éªŒè¯å’Œæ ‡å‡†åŒ–
            symbol = self._validate_symbol(symbol)
            start_dt, end_dt, original_start, original_end = self._validate_dates(start_date, end_date)
            
            # æ£€æŸ¥ç¼“å­˜
            cache_start = original_start if original_start else start_dt.strftime("%Y%m%d")
            cache_end = original_end if original_end else end_dt.strftime("%Y%m%d")
            cache_key = self._get_cache_key('weekly', symbol, cache_start, cache_end)
            
            cached_data = self._get_from_cache(cache_key)
            if cached_data is not None:
                # ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ æ–°å¢ï¼šè®°å½•ç¼“å­˜æ•°æ®çš„æ—¥æœŸèŒƒå›´
                if not cached_data.empty and 'date' in cached_data.columns:
                    cache_start_date = cached_data['date'].min().strftime('%Y-%m-%d')
                    cache_end_date = cached_data['date'].max().strftime('%Y-%m-%d')
                    cache_days = (cached_data['date'].max() - cached_data['date'].min()).days
                    logger.info(f"ç¼“å­˜æ•°æ®æ—¥æœŸèŒƒå›´: {cache_start_date} è‡³ {cache_end_date} (å…±{cache_days}å¤©)")
                
                logger.info(f"ä»ç¼“å­˜è·å–å‘¨çº¿æ•°æ®: {symbol}")
                return cached_data
            
            # æ ¹æ®çº¯æ•°å­—ä»£ç ç¡®å®šå¸‚åœºå‰ç¼€
            market = self._get_market_prefix(symbol)
            full_symbol = f"{market}{symbol}"  # ç”¨äºè¯·æ±‚çš„ä»£ç 
            
            # æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªæ•°æ®æº
            for source in self.data_sources:
                try:
                    if source == 'tencent':
                        df = self._get_tencent_weekly_data(symbol, start_dt, end_dt, full_symbol)
                    elif source == 'sina':
                        df = self._get_sina_weekly_data(symbol, start_dt, end_dt, full_symbol)
                    else:
                        continue
                    
                    # ä½¿ç”¨å®‰å…¨çš„DataFrameæ£€æŸ¥
                    if df is not None and not df.empty:
                        # ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ æ–°å¢ï¼šè®°å½•å®é™…è·å–æ•°æ®çš„æ—¥æœŸèŒƒå›´
                        if 'date' in df.columns:
                            actual_start = df['date'].min().strftime('%Y-%m-%d')
                            actual_end = df['date'].max().strftime('%Y-%m-%d')
                            actual_days = (df['date'].max() - df['date'].min()).days
                            logger.info(f"æ•°æ®æºè¿”å›çš„å®é™…æ—¥æœŸèŒƒå›´: {actual_start} è‡³ {actual_end} (å…±{actual_days}å¤©)")
                        
                        # ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æ—¥æœŸèŒƒå›´å®Œæ•´æ€§
                        self._check_date_range_completeness(df, start_dt, end_dt, symbol, 'weekly')
                        
                        self._save_to_cache(cache_key, df)
                        logger.info(f"æˆåŠŸä» {source} è·å–å‘¨çº¿æ•°æ®: {len(df)} æ¡")
                        return df
                        
                except Exception as e:
                    logger.warning(f"æ•°æ®æº {source} å¤±è´¥: {str(e)}")
                    continue
            
            logger.error("æ‰€æœ‰å‘¨çº¿æ•°æ®è·å–æ–¹å¼å‡å¤±è´¥")
            return pd.DataFrame()
            
        except DataFetchError as e:
            logger.error(f"è·å–å‘¨çº¿æ•°æ®å‚æ•°é”™è¯¯: {str(e)}")
            return pd.DataFrame()
        except Exception as e:
            logger.error(f"è·å–å‘¨çº¿æ•°æ®å¼‚å¸¸: {str(e)}")
            return pd.DataFrame()
    
    def _get_tencent_weekly_data(self, symbol: str, start_dt: datetime, 
                                end_dt: datetime, full_symbol: str) -> pd.DataFrame:
        """
        è·å–è…¾è®¯è´¢ç»å‘¨çº¿æ•°æ® - å¢å¼ºé”™è¯¯å¤„ç†
        """
        try:
            if not self.tencent_enabled:
                return pd.DataFrame()
            
            timestamp = int(time.time() * 1000)
            param_str = f"{full_symbol},week,{start_dt.strftime('%Y-%m-%d')},{end_dt.strftime('%Y-%m-%d')},500,qfq"
            params = {
                "_var": self.tencent_params['weekly']['_var'],
                "param": param_str,
                "r": f"0.{timestamp}"
            }
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Referer': 'https://gu.qq.com/'
            }
            
            def fetch_func():
                try:
                    response = requests.get(self.tencent_weekly_url, params=params, 
                                          headers=headers, timeout=self.timeout)
                    if response.status_code != 200:
                        return pd.DataFrame()
                    
                    content = response.text.strip()
                    if not content:
                        return pd.DataFrame()
                    
                    # ä¿®å¤JSONè§£æé€»è¾‘
                    json_str = content
                    if content.startswith('kline_week='):
                        json_str = content[11:]
                    
                    if json_str.endswith(';'):
                        json_str = json_str[:-1]
                    
                    data = json.loads(json_str)
                    
                    # è…¾è®¯æ¥å£è¿”å›çš„æ•°æ®ç»“æ„éªŒè¯
                    if 'data' not in data or 'code' not in data:
                        return pd.DataFrame()
                    
                    if data.get('code') != 0:
                        return pd.DataFrame()
                    
                    stock_data = data.get('data', {})
                    if full_symbol not in stock_data:
                        return pd.DataFrame()
                    
                    symbol_data = stock_data[full_symbol]
                    
                    # æŸ¥æ‰¾å‘¨çº¿æ•°æ®é”®
                    weekly_keys = ['qfqweek', 'week', 'qfqWeek', 'Week']
                    weekly_data = None
                    
                    for key in weekly_keys:
                        if key in symbol_data:
                            weekly_data = symbol_data[key]
                            break
                    
                    if not weekly_data:
                        return pd.DataFrame()
                    
                    # è½¬æ¢ä¸ºDataFrame
                    columns = ['date', 'open', 'close', 'high', 'low', 'volume']
                    df = pd.DataFrame(weekly_data, columns=columns)
                    
                    # ä½¿ç”¨å®‰å…¨çš„DataFrameæ“ä½œ
                    df = self._safe_dataframe_operation(df, 'convert_dtypes', 
                                                       date_col='date',
                                                       numeric_cols=['open', 'close', 'high', 'low', 'volume'])
                    
                    df = self._safe_dataframe_operation(df, 'add_column', 
                                                       column_name='symbol', column_value=full_symbol)
                    
                    # è¿‡æ»¤æ—¥æœŸèŒƒå›´
                    if not df.empty and 'date' in df.columns:
                        df = df[(df['date'] >= start_dt) & (df['date'] <= end_dt)]
                    
                    return df
                    
                except Exception as e:
                    logger.warning(f"è…¾è®¯æ•°æ®è¯·æ±‚å¼‚å¸¸: {str(e)}")
                    return pd.DataFrame()
            
            result = self._request_with_retry(fetch_func)
            return result if result is not None else pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å–è…¾è®¯å‘¨çº¿æ•°æ®å¼‚å¸¸: {str(e)}")
            return pd.DataFrame()
    
    def _get_sina_weekly_data(self, symbol: str, start_dt: datetime, 
                             end_dt: datetime, full_symbol: str) -> pd.DataFrame:
        """
        è·å–æ–°æµªå‘¨çº¿æ•°æ® - å¢å¼ºé”™è¯¯å¤„ç†
        """
        try:
            # å°è¯•ä¸åŒçš„scaleå€¼è·å–å‘¨çº¿æ•°æ®
            scale_options = ["240", "60", "30", "15", "week"]
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Referer': 'http://finance.sina.com.cn/'
            }
            
            def fetch_func():
                for scale_val in scale_options:
                    params = {
                        "symbol": full_symbol,
                        "scale": scale_val,
                        "ma": "no",
                        "datalen": "500"
                    }
                    
                    try:
                        response = requests.get(self.sina_base_url, params=params, 
                                              headers=headers, timeout=self.timeout)
                        if response.status_code != 200:
                            continue
                        
                        content = response.text.strip()
                        if not content or content == "null":
                            continue
                        
                        data = json.loads(content)
                        if not data or not isinstance(data, list):
                            continue
                        
                        # è½¬æ¢ä¸ºDataFrame
                        df = pd.DataFrame(data)
                        
                        # å®‰å…¨é‡å‘½ååˆ—
                        column_map = {
                            "day": "date",
                            "open": "open",
                            "high": "high",
                            "low": "low",
                            "close": "close",
                            "volume": "volume"
                        }
                        df = self._safe_dataframe_operation(df, 'rename', column_map=column_map)
                        
                        # å®‰å…¨è½¬æ¢æ•°æ®ç±»å‹
                        df = self._safe_dataframe_operation(df, 'convert_dtypes',
                                                           date_col='date',
                                                           numeric_cols=['open', 'close', 'high', 'low', 'volume'])
                        
                        df = self._safe_dataframe_operation(df, 'add_column',
                                                           column_name='symbol', column_value=full_symbol)
                        
                        # å®‰å…¨è¿‡æ»¤æ—¥æœŸèŒƒå›´
                        if not df.empty and 'date' in df.columns:
                            df = df[(df['date'] >= start_dt) & (df['date'] <= end_dt)]
                        
                        if not df.empty:
                            return df
                            
                    except Exception as e:
                        continue
                
                return pd.DataFrame()
            
            result = self._request_with_retry(fetch_func)
            return result if result is not None else pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å–æ–°æµªå‘¨çº¿æ•°æ®å¼‚å¸¸: {str(e)}")
            return pd.DataFrame()
    
    def get_daily_data(self, symbol: str, start_date: Optional[str] = None, 
                      end_date: Optional[str] = None) -> pd.DataFrame:
        """
        è·å–æ—¥çº¿æ•°æ® - å¢å¼ºé”™è¯¯å¤„ç†å’Œæ—¥æœŸæ—¥å¿—
        :param symbol: è‚¡ç¥¨ä»£ç 
        :param start_date: å¼€å§‹æ—¥æœŸ
        :param end_date: ç»“æŸæ—¥æœŸ
        :return: æ—¥çº¿æ•°æ®DataFrame
        """
        try:
            # ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ å¢å¼ºæ—¥å¿—ï¼šè®°å½•æ–¹æ³•è°ƒç”¨å‚æ•°
            logger.info(f"è·å–æ—¥çº¿æ•°æ® - ç¬¦å·: {symbol}, å¼€å§‹: {start_date}, ç»“æŸ: {end_date}")
            
            symbol = self._validate_symbol(symbol)
            start_dt, end_dt, original_start, original_end = self._validate_dates(start_date, end_date)
            
            cache_key = self._get_cache_key('daily', symbol, 
                                           start_dt.strftime("%Y%m%d"), 
                                           end_dt.strftime("%Y%m%d"))
            cached_data = self._get_from_cache(cache_key)
            if cached_data is not None:
                logger.info(f"ä»ç¼“å­˜è·å–æ—¥çº¿æ•°æ®: {symbol}")
                return cached_data
            
            # æ ¹æ®çº¯æ•°å­—ä»£ç ç¡®å®šå¸‚åœºå‰ç¼€
            market = self._get_market_prefix(symbol)
            full_symbol = f"{market}{symbol}"  # ç”¨äºè¯·æ±‚çš„ä»£ç 
            
            params = {
                "symbol": full_symbol,
                "scale": "240",
                "ma": "no",
                "datalen": "1000"
            }
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Referer': 'http://finance.sina.com.cn/'
            }
            
            def fetch_func():
                try:
                    response = requests.get(self.sina_base_url, params=params, 
                                          headers=headers, timeout=self.timeout)
                    if response.status_code != 200:
                        return pd.DataFrame()
                    
                    content = response.text.strip()
                    if not content or content == "null":
                        return pd.DataFrame()
                    
                    data = json.loads(content)
                    if not data or not isinstance(data, list):
                        return pd.DataFrame()
                    
                    # è½¬æ¢ä¸ºDataFrame
                    df = pd.DataFrame(data)
                    
                    # å®‰å…¨é‡å‘½ååˆ—
                    column_map = {
                        "day": "date",
                        "open": "open",
                        "high": "high",
                        "low": "low",
                        "close": "close",
                        "volume": "volume"
                    }
                    df = self._safe_dataframe_operation(df, 'rename', column_map=column_map)
                    
                    # å®‰å…¨è½¬æ¢æ•°æ®ç±»å‹
                    df = self._safe_dataframe_operation(df, 'convert_dtypes',
                                                       date_col='date',
                                                       numeric_cols=['open', 'close', 'high', 'low', 'volume'])
                    
                    df = self._safe_dataframe_operation(df, 'add_column',
                                                       column_name='symbol', column_value=full_symbol)
                    
                    # å®‰å…¨è¿‡æ»¤æ—¥æœŸèŒƒå›´
                    if not df.empty and 'date' in df.columns:
                        df = df[(df['date'] >= start_dt) & (df['date'] <= end_dt)]
                    
                    return df
                    
                except Exception as e:
                    return pd.DataFrame()
            
            result = self._request_with_retry(fetch_func)
            if result is not None and not result.empty:
                # ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æ—¥æœŸèŒƒå›´å®Œæ•´æ€§
                self._check_date_range_completeness(result, start_dt, end_dt, symbol, 'daily')
                
                self._save_to_cache(cache_key, result)
                logger.info(f"æˆåŠŸè·å–æ—¥çº¿æ•°æ®: {len(result)} æ¡")
                return result
            
            return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å–æ—¥çº¿æ•°æ®å¼‚å¸¸: {str(e)}")
            return pd.DataFrame()
    
    def get_realtime_data(self, symbol: str) -> Dict:
        """
        è·å–å®æ—¶æ•°æ® - å¢å¼ºé”™è¯¯å¤„ç†
        :param symbol: è‚¡ç¥¨ä»£ç 
        :return: å®æ—¶æ•°æ®å­—å…¸
        """
        try:
            symbol = self._validate_symbol(symbol)
            
            # æ ¹æ®çº¯æ•°å­—ä»£ç ç¡®å®šå¸‚åœºå‰ç¼€
            market = self._get_market_prefix(symbol)
            full_symbol = f"{market}{symbol}"  # ç”¨äºè¯·æ±‚çš„ä»£ç 
            
            url = f"https://qt.gtimg.cn/q={full_symbol}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Referer': 'https://gu.qq.com/'
            }
            
            def fetch_func():
                try:
                    response = requests.get(url, headers=headers, timeout=self.timeout)
                    if response.status_code != 200:
                        return {}
                    
                    content = response.text.strip()
                    if not content:
                        return {}
                    
                    # è§£æè…¾è®¯è´¢ç»å®æ—¶æ•°æ®æ ¼å¼
                    if '~' not in content:
                        return {}
                    
                    parts = content.split('~')
                    if len(parts) < 40:
                        return {}
                    
                    # æå–å…³é”®å­—æ®µ
                    data = {
                        'name': parts[1],
                        'code': parts[2],
                        'price': parts[3],
                        'prev_close': parts[4],
                        'open': parts[5],
                        'volume': parts[6],
                        'amount': parts[37] if len(parts) > 37 else '0',
                        'high': parts[33] if len(parts) > 33 else '0',
                        'low': parts[34] if len(parts) > 34 else '0',
                        'time': parts[30] if len(parts) > 30 else ''
                    }
                    
                    # å®‰å…¨è½¬æ¢æ•°å€¼ç±»å‹
                    for key in ['price', 'prev_close', 'open', 'volume', 'amount', 'high', 'low']:
                        try:
                            data[key] = float(data[key])
                        except (ValueError, TypeError):
                            data[key] = 0.0
                    
                    return data
                except Exception as e:
                    logger.warning(f"å®æ—¶æ•°æ®è¯·æ±‚å¼‚å¸¸: {str(e)}")
                    return {}
            
            return self._request_with_retry(fetch_func) or {}
            
        except Exception as e:
            logger.error(f"è·å–å®æ—¶æ•°æ®å¼‚å¸¸: {str(e)}")
            return {}
    
    def get_minute_data(self, symbol: str, interval: str = '5m', days: int = 30) -> pd.DataFrame:
        """
        è·å–åˆ†é’Ÿæ•°æ® - æ¨¡æ‹Ÿå®ç°ï¼ŒåŸºäºæ—¥çº¿æ•°æ®ç”Ÿæˆ
        :param symbol: è‚¡ç¥¨ä»£ç 
        :param interval: æ—¶é—´é—´éš”ï¼Œå¦‚'5m'
        :param days: å¤©æ•°
        :return: åˆ†é’Ÿæ•°æ®DataFrame
        """
        try:
            # æ¨¡æ‹Ÿå®ç°ï¼šè·å–æ—¥çº¿æ•°æ®ï¼Œç„¶åç”Ÿæˆåˆ†é’Ÿæ•°æ®
            end_date = datetime.now().strftime("%Y%m%d")
            start_date = (datetime.now() - timedelta(days=days)).strftime("%Y%m%d")
            daily_data = self.get_daily_data(symbol, start_date, end_date)
            if daily_data.empty:
                return pd.DataFrame()
            
            # ç”Ÿæˆåˆ†é’Ÿæ•°æ®ï¼šæ¯ä¸ªäº¤æ˜“æ—¥ç”Ÿæˆ240ä¸ªåˆ†é’Ÿç‚¹ï¼ˆæ¨¡æ‹Ÿï¼‰
            minute_data = []
            for _, row in daily_data.iterrows():
                date = row['date']
                # ç¡®ä¿dateæ˜¯datetimeå¯¹è±¡
                if isinstance(date, str):
                    date = pd.to_datetime(date)
                for i in range(240):  # å‡è®¾äº¤æ˜“æ—¥æœ‰4å°æ—¶ï¼Œ240åˆ†é’Ÿ
                    minute_time = date + timedelta(minutes=i)
                    # æ¨¡æ‹Ÿä»·æ ¼æ³¢åŠ¨ï¼ŒåŸºäºæ—¥çº¿OHLC
                    progress = i / 239.0
                    minute_open = row['open'] + (row['close'] - row['open']) * progress
                    minute_high = row['high']  # ç®€åŒ–
                    minute_low = row['low']    # ç®€åŒ–
                    minute_close = minute_open  # ç®€åŒ–
                    minute_volume = row['volume'] / 240  # å¹³å‡åˆ†é…
                    minute_data.append({
                        'date': minute_time,
                        'open': minute_open,
                        'high': minute_high,
                        'low': minute_low,
                        'close': minute_close,
                        'volume': minute_volume
                    })
            df = pd.DataFrame(minute_data)
            df = self._safe_dataframe_operation(df, 'add_column', column_name='symbol', column_value=symbol)
            return df
        except Exception as e:
            logger.error(f"è·å–åˆ†é’Ÿæ•°æ®å¼‚å¸¸: {str(e)}")
            return pd.DataFrame()
    
    def health_check(self) -> Dict:
        """
        å¥åº·æ£€æŸ¥ - å¢å¼ºé”™è¯¯å¤„ç†
        :return: ç³»ç»ŸçŠ¶æ€å­—å…¸
        """
        try:
            status_info = {
                "status": "OK",
                "version": "2.1.1",
                "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "data_sources": self.data_sources,
                "cache_enabled": self.cache_enabled,
                "cache_size": len(self.cache),
                "features": self._get_feature_summary()
            }
            
            # æµ‹è¯•æ•°æ®è·å–åŠŸèƒ½
            try:
                test_symbol = "000001"  # çº¯æ•°å­—ä»£ç 
                test_data = self.get_realtime_data(test_symbol)
                if test_data:
                    status_info["realtime_test"] = "PASS"
                else:
                    status_info["realtime_test"] = "FAIL"
            except:
                status_info["realtime_test"] = "FAIL"
            
            return status_info
            
        except Exception as e:
            logger.error(f"å¥åº·æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            return {
                "status": "ERROR",
                "error": str(e),
                "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }

# å‘åå…¼å®¹æ€§åˆ«å
StockDataAPI = StockDataFetcher

# åŠŸèƒ½å®Œæ•´æ€§æµ‹è¯•
def test_feature_completeness():
    """æµ‹è¯•æ‰€æœ‰åŠŸèƒ½æ¨¡å—æ˜¯å¦å®Œæ•´å®ç°"""
    print("=== åŠŸèƒ½å®Œæ•´æ€§æ£€æŸ¥ ===")
    
    fetcher = StockDataFetcher()
    
    # æµ‹è¯•1: å¥åº·æ£€æŸ¥
    print("1. å¥åº·æ£€æŸ¥...")
    health = fetcher.health_check()
    print(f"   çŠ¶æ€: {health['status']}")
    print(f"   ç‰ˆæœ¬: {health['version']}")
    print(f"   åŠŸèƒ½: {health['features']}")
    
    # æµ‹è¯•2: å®æ—¶æ•°æ®è·å–
    print("2. å®æ—¶æ•°æ®è·å–...")
    realtime_data = fetcher.get_realtime_data("000001")  # çº¯æ•°å­—ä»£ç 
    if realtime_data:
        print(f"   æˆåŠŸè·å–å®æ—¶æ•°æ®: {realtime_data.get('name', 'N/A')}")
    else:
        print("   å®æ—¶æ•°æ®è·å–å¤±è´¥")
    
    # æµ‹è¯•3: æ—¥çº¿æ•°æ®è·å–
    print("3. æ—¥çº¿æ•°æ®è·å–...")
    daily_data = fetcher.get_daily_data("000001", "2023-10-01", "2023-10-10")
    if not daily_data.empty:
        print(f"   æˆåŠŸè·å–æ—¥çº¿æ•°æ®: {len(daily_data)} æ¡")
    else:
        print("   æ—¥çº¿æ•°æ®è·å–å¤±è´¥")
    
    # æµ‹è¯•4: å‘¨çº¿æ•°æ®è·å–
    print("4. å‘¨çº¿æ•°æ®è·å–...")
    weekly_data = fetcher.get_weekly_data("000001", "2023-01-01", "2023-10-01")
    if not weekly_data.empty:
        print(f"   æˆåŠŸè·å–å‘¨çº¿æ•°æ®: {len(weekly_data)} æ¡")
    else:
        print("   å‘¨çº¿æ•°æ®è·å–å¤±è´¥")
    
    # æµ‹è¯•5: åˆ†é’Ÿæ•°æ®è·å–
    print("5. åˆ†é’Ÿæ•°æ®è·å–...")
    minute_data = fetcher.get_minute_data("000001", "5m", 30)
    if not minute_data.empty:
        print(f"   æˆåŠŸè·å–åˆ†é’Ÿæ•°æ®: {len(minute_data)} æ¡")
    else:
        print("   åˆ†é’Ÿæ•°æ®è·å–å¤±è´¥")
    
    # æµ‹è¯•6: ç¼“å­˜åŠŸèƒ½
    print("6. ç¼“å­˜åŠŸèƒ½æµ‹è¯•...")
    if fetcher.cache_enabled:
        print("   ç¼“å­˜åŠŸèƒ½å·²å¯ç”¨")
    else:
        print("   ç¼“å­˜åŠŸèƒ½æœªå¯ç”¨")
    
    print("=== æ£€æŸ¥å®Œæˆ ===")

if __name__ == "__main__":
    # è¿è¡ŒåŠŸèƒ½å®Œæ•´æ€§æµ‹è¯•
    test_feature_completeness()
    
    # è¯¦ç»†åŠŸèƒ½æ¼”ç¤º
    print("\n=== è¯¦ç»†åŠŸèƒ½æ¼”ç¤º ===")
    fetcher = StockDataFetcher()
    
    # æ¼”ç¤ºå‘¨çº¿æ•°æ®è·å–
    symbol = "000001"  # çº¯æ•°å­—ä»£ç 
    weekly_data = fetcher.get_weekly_data(symbol, "2023-01-01", "2023-10-01")
    
    if not weekly_data.empty:
        print(f"æˆåŠŸè·å– {symbol} å‘¨çº¿æ•°æ®:")
        print(f"æ•°æ®èŒƒå›´: {weekly_data['date'].min()} è‡³ {weekly_data['date'].max()}")
        print(f"æ•°æ®åˆ—: {list(weekly_data.columns)}")
        print(weekly_data.head())
    else:
        print("å‘¨çº¿æ•°æ®è·å–å¤±è´¥")
    
    # æ¼”ç¤ºå®æ—¶æ•°æ®
    realtime_data = fetcher.get_realtime_data(symbol)
    if realtime_data:
        print(f"\n{realtime_data.get('name', symbol)} å®æ—¶æ•°æ®:")
        for key, value in realtime_data.items():
            print(f"  {key}: {value}")
    
    # æ¼”ç¤ºåˆ†é’Ÿæ•°æ®
    minute_data = fetcher.get_minute_data(symbol, "5m", 1)  # 1å¤©çš„åˆ†é’Ÿæ•°æ®
    if not minute_data.empty:
        print(f"\næˆåŠŸè·å– {symbol} åˆ†é’Ÿæ•°æ®:")
        print(f"æ•°æ®ç‚¹æ•°: {len(minute_data)}")
        print(minute_data.head())
    else:
        print("åˆ†é’Ÿæ•°æ®è·å–å¤±è´¥")