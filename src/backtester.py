#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç¼ è®ºå›æµ‹ç³»ç»Ÿ - ä¿®å¤ç‰ˆæœ¬
ä¿®å¤äº†æ—¥æœŸèŒƒå›´ä¸æ­£ç¡®ã€ç¬¦å·éªŒè¯ã€å¯¼å…¥é”™è¯¯å’Œé…ç½®KeyErroré—®é¢˜
"""

import sys
import os
import argparse
import logging
import pandas as pd
import numpy as np
import re
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import json
import warnings
from typing import Dict, List, Optional, Tuple, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# ç›´æ¥å¯¼å…¥ä¾èµ–æ¨¡å—ï¼ˆå½»åº•ç§»é™¤validate_trading_dateï¼‰
try:
    from src.config import load_config, save_config
    from src.data_fetcher import StockDataAPI, DataFetchError
    from src.calculator import ChanlunCalculator
    from src.notifier import DingdingNotifier
    from src.utils import get_last_trading_day, is_trading_hour, get_valid_date_range_str
    from src.reporter import generate_pre_market_report, generate_daily_report
    from src.exporter import ChanlunExporter
    from src.plotter import ChanlunPlotter
except ImportError as e:
    logging.error(f"å¯¼å…¥ä¾èµ–æ¨¡å—å¤±è´¥: {e}")
    raise

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('backtest.log', encoding='utf-8')
    ]
)
logger = logging.getLogger('ChanlunBacktest')

class BacktestEngine:
    """ç¼ è®ºå›æµ‹å¼•æ“æ ¸å¿ƒç±» - ä¿®å¤æ—¥æœŸèŒƒå›´å’Œç¬¦å·éªŒè¯é—®é¢˜"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–å›æµ‹å¼•æ“
        :param config: ç³»ç»Ÿé…ç½®
        """
        self.config = config
        self.data_api = None
        self.calculator = None
        self.notifier = None
        self.plotter = None
        self.exporter = None
        
        self._initialize_components()
        logger.info("ç¼ è®ºå›æµ‹å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶ï¼ˆé…ç½®è®¿é—®ä½¿ç”¨getæ–¹æ³•ï¼‰"""
        # åˆå§‹åŒ–æ•°æ®API
        data_fetcher_config = self.config.get('data_fetcher', {})
        self.data_api = StockDataAPI(
            max_retries=data_fetcher_config.get('max_retries', 3),
            timeout=data_fetcher_config.get('timeout', 10)
        )
        
        # åˆå§‹åŒ–è®¡ç®—å™¨
        chanlun_config = self.config.get('chanlun', {})
        self.calculator = ChanlunCalculator(chanlun_config)
        
        # åˆå§‹åŒ–é€šçŸ¥å™¨ï¼ˆå…¼å®¹æ— notificationsé…ç½®ï¼‰
        self.notifier = DingdingNotifier(self.config)
        
        # åˆå§‹åŒ–ç»˜å›¾å™¨
        plotter_config = self.config.get('plotter', {})
        self.plotter = ChanlunPlotter(plotter_config)
        
        # åˆå§‹åŒ–æ•°æ®å¯¼å‡ºå™¨
        self.exporter = ChanlunExporter(self.config.get('exporter', {}))
    
    def run_comprehensive_backtest(self, symbol: str, start_date: str, end_date: str, 
                                  timeframe: str = 'weekly', initial_capital: float = 100000) -> Dict[str, Any]:
        """
        è¿è¡Œå…¨é¢å›æµ‹ - ä¿®å¤æ—¥æœŸèŒƒå›´é—®é¢˜
        :param symbol: è‚¡ç¥¨ä»£ç 
        :param start_date: å¼€å§‹æ—¥æœŸ
        :param end_date: ç»“æŸæ—¥æœŸ
        :param timeframe: æ—¶é—´çº§åˆ«
        :param initial_capital: åˆå§‹èµ„é‡‘
        :return: å®Œæ•´å›æµ‹ç»“æœ
        """
        # å¢å¼ºæ—¥å¿—ï¼šè®°å½•åŸå§‹æ—¥æœŸå‚æ•°
        logger.info(f"å¼€å§‹å…¨é¢å›æµ‹: {symbol} {timeframe}")
        logger.info(f"ç”¨æˆ·æŒ‡å®šæ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")
        logger.info(f"åˆå§‹èµ„é‡‘: {initial_capital}")
        
        try:
            # é˜²å¾¡æ€§æ£€æŸ¥ï¼šéªŒè¯symbolä¸æ˜¯DataFrame
            self._validate_symbol_not_dataframe(symbol)
            
            # 1. æ•°æ®è·å–é˜¶æ®µ - ä¿®å¤æ—¥æœŸå¤„ç†
            data_result = self._acquire_and_validate_data(symbol, start_date, end_date, timeframe)
            if not data_result['success']:
                error_msg = f"æ•°æ®è·å–å¤±è´¥: {data_result['error']}"
                logger.error(error_msg)
                return self._create_error_result(initial_capital, error_msg)
            
            df = data_result['data']
            actual_start = df['date'].min().strftime('%Y-%m-%d')
            actual_end = df['date'].max().strftime('%Y-%m-%d')
            logger.info(f"æ•°æ®è·å–æˆåŠŸ: {len(df)}æ¡è®°å½•, å®é™…æ—¥æœŸèŒƒå›´: {actual_start} è‡³ {actual_end}")
            
            # 2. ç¼ è®ºè®¡ç®—é˜¶æ®µ
            calculation_result = self._perform_chanlun_calculation(df, timeframe)
            if not calculation_result['success']:
                error_msg = f"ç¼ è®ºè®¡ç®—å¤±è´¥: {calculation_result['error']}"
                logger.error(error_msg)
                return self._create_error_result(initial_capital, error_msg)
            
            calculated_df = calculation_result['data']
            
            # 3. å›æµ‹æ‰§è¡Œé˜¶æ®µ
            backtest_result = self._execute_backtest(calculated_df, initial_capital, timeframe)
            if not backtest_result['success']:
                error_msg = f"å›æµ‹æ‰§è¡Œå¤±è´¥: {backtest_result['error']}"
                logger.error(error_msg)
                return self._create_error_result(initial_capital, error_msg)
            
            result = backtest_result['data']
            
            # 4. æŠ¥å‘Šç”Ÿæˆé˜¶æ®µ
            report_result = self._generate_comprehensive_report(result, symbol, timeframe)
            result['report'] = report_result
            
            # 5. å›¾è¡¨ç”Ÿæˆé˜¶æ®µï¼ˆå…¼å®¹æ— plotteré…ç½®ï¼‰
            if self.config.get('plotter', {}).get('enabled', False):
                chart_result = self._generate_detailed_charts(result, symbol, timeframe)
            else:
                chart_result = {'success': False, 'error': 'å›¾è¡¨ç”Ÿæˆæœªå¯ç”¨'}
            result['charts'] = chart_result
            
            # 6. é€šçŸ¥å‘é€é˜¶æ®µï¼ˆå…¼å®¹æ— notificationsé…ç½®ï¼‰
            if self.config.get('notifications', {}).get('enabled', False):
                self._send_notifications(result, symbol, timeframe)
            
            # è®°å½•å®é™…ä½¿ç”¨çš„æ—¥æœŸèŒƒå›´
            result['actual_date_range'] = {
                'start': actual_start,
                'end': actual_end,
                'requested_start': start_date,
                'requested_end': end_date
            }
            
            logger.info(f"å…¨é¢å›æµ‹å®Œæˆ: æ€»å›æŠ¥{result.get('return_percent', 0):.2f}%, å®é™…æ—¥æœŸèŒƒå›´: {actual_start} è‡³ {actual_end}")
            return result
            
        except Exception as e:
            error_msg = f"å›æµ‹è¿‡ç¨‹å¼‚å¸¸: {str(e)}"
            logger.error(error_msg)
            return self._create_error_result(initial_capital, error_msg)
    
    def _validate_symbol_not_dataframe(self, symbol: Any):
        """
        ä¼˜åŒ–çš„ç¬¦å·éªŒè¯æ–¹æ³•ï¼šç¡®ä¿symbolæ˜¯æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç è€ŒéDataFrameæˆ–å…¶ä»–æ— æ•ˆç±»å‹
        æ ¸å¿ƒä¼˜åŒ–ï¼šæ›´ç²¾å‡†çš„ç±»å‹æ£€æµ‹ã€æ›´å‹å¥½çš„é”™è¯¯æç¤ºã€æ›´å…¨é¢çš„æ ¼å¼éªŒè¯
        :param symbol: è¦æ£€æŸ¥çš„ç¬¦å·
        """
        # æ£€æŸ¥æ˜¯å¦ä¸ºNone
        if symbol is None:
            logger.critical("è‚¡ç¥¨ä»£ç å‚æ•°ä¸ºNoneï¼Œæ— æ³•æ‰§è¡Œå›æµ‹")
            raise ValueError("è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºNone")
        
        # ç›´æ¥æ£€æŸ¥æ˜¯å¦ä¸ºPandas DataFrameæˆ–Seriesï¼ˆæ ¸å¿ƒä¿®å¤ç‚¹ï¼‰
        if isinstance(symbol, pd.DataFrame):
            logger.critical(f"æ£€æµ‹åˆ°Pandas DataFrameä½œä¸ºè‚¡ç¥¨ä»£ç ï¼Œæ•°æ®å½¢çŠ¶: {symbol.shape}")
            raise ValueError("æ— æ•ˆè‚¡ç¥¨ä»£ç ç±»å‹: ä¸èƒ½å°†DataFrameå¯¹è±¡ä½œä¸ºè‚¡ç¥¨ä»£ç ä¼ é€’")
        elif isinstance(symbol, pd.Series):
            logger.critical(f"æ£€æµ‹åˆ°Pandas Seriesä½œä¸ºè‚¡ç¥¨ä»£ç ï¼Œæ•°æ®é•¿åº¦: {len(symbol)}")
            raise ValueError("æ— æ•ˆè‚¡ç¥¨ä»£ç ç±»å‹: ä¸èƒ½å°†Serieså¯¹è±¡ä½œä¸ºè‚¡ç¥¨ä»£ç ä¼ é€’")
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ¸…ç†ï¼ˆå¤„ç†éå­—ç¬¦ä¸²è¾“å…¥ï¼‰
        try:
            symbol_str = str(symbol).strip()
        except Exception as e:
            logger.critical(f"æ— æ³•å°†è‚¡ç¥¨ä»£ç è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œè¾“å…¥ç±»å‹: {type(symbol)}ï¼Œé”™è¯¯: {str(e)}")
            raise ValueError(f"è‚¡ç¥¨ä»£ç æ ¼å¼æ— æ•ˆï¼Œæ— æ³•è½¬æ¢ä¸ºå­—ç¬¦ä¸²: {str(e)}")
        
        # æ£€æŸ¥å­—ç¬¦ä¸²é•¿åº¦æ˜¯å¦åˆç†ï¼ˆæ­£å¸¸è‚¡ç¥¨ä»£ç ä¸ä¼šè¶…è¿‡20å­—ç¬¦ï¼‰
        if len(symbol_str) > 20:
            logger.critical(f"è‚¡ç¥¨ä»£ç è¿‡é•¿({len(symbol_str)}å­—ç¬¦)ï¼Œç–‘ä¼¼æ— æ•ˆè¾“å…¥: {symbol_str[:50]}...")
            raise ValueError(f"è‚¡ç¥¨ä»£ç è¿‡é•¿ï¼ˆè¶…è¿‡20å­—ç¬¦ï¼‰ï¼Œå¯èƒ½æ˜¯è¯¯ä¼ çš„DataFrame/Serieså­—ç¬¦ä¸²è¡¨ç¤º")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«DataFrameç›¸å…³ç‰¹å¾å…³é”®è¯ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼Œç²¾å‡†åŒ¹é…ï¼‰
        dataframe_indicators = [
            'DataFrame', 'Series', 'open', 'high', 'low', 'close', 'volume', 'date',
            'timestamp', 'adj_close', 'amount', 'turnover', 'pe', 'pb'
        ]
        matched_indicators = [ind for ind in dataframe_indicators if ind.lower() in symbol_str.lower()]
        if matched_indicators:
            logger.critical(f"è‚¡ç¥¨ä»£ç åŒ…å«DataFrameç‰¹å¾å…³é”®è¯: {matched_indicators}ï¼Œè¾“å…¥å€¼: {symbol_str[:200]}")
            raise ValueError(f"æ— æ•ˆè‚¡ç¥¨ä»£ç : åŒ…å«'{matched_indicators[0]}'ç­‰æ•°æ®åˆ—åæˆ–Pandaså¯¹è±¡å…³é”®è¯")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç æ ¼å¼ï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡å¸¸è§æ ¼å¼ï¼‰
        pattern = r'^([a-zA-Z]{2})?(\d{5,6}|\w{1,5})(\.[A-Za-z]{2})?$'
        if not re.match(pattern, symbol_str):
            logger.warning(
                f"è‚¡ç¥¨ä»£ç æ ¼å¼ä¸æ ‡å‡†: {symbol_str}\n"
                f"å»ºè®®æ ¼å¼ï¼š\n"
                f"- Aè‚¡: 000001 / sh000001 / 000001.SH\n"
                f"- æ¸¯è‚¡: HK00700 / 00700.HK\n"
                f"- ç¾è‚¡: AAPL / AAPL.US"
            )
    
    def _acquire_and_validate_data(self, symbol: str, start_date: str, end_date: str, 
                                  timeframe: str) -> Dict[str, Any]:
        """
        è·å–å¹¶éªŒè¯æ•°æ® - ä¿®å¤æ—¥æœŸèŒƒå›´é—®é¢˜
        :return: åŒ…å«æˆåŠŸçŠ¶æ€å’Œæ•°æ®çš„ç»“æœå­—å…¸
        """
        try:
            logger.info(f"æ•°æ®è·å–é˜¶æ®µ - ç¬¦å·: {symbol}, æ—¶é—´çº§åˆ«: {timeframe}")
            logger.info(f"è¯·æ±‚æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")
            
            # ç®€å•æ—¥æœŸæ ¼å¼éªŒè¯ï¼ˆä¸ä¾èµ–å¤–éƒ¨å‡½æ•°ï¼‰
            def parse_simple_date(date_str: str) -> datetime:
                """ç®€å•æ—¥æœŸè§£æï¼ˆæ”¯æŒYYYYMMDDå’ŒYYYY-MM-DDï¼‰"""
                date_str = str(date_str).strip()
                try:
                    if len(date_str) == 8 and date_str.isdigit():
                        return datetime.strptime(date_str, '%Y%m%d')
                    else:
                        return datetime.strptime(date_str, '%Y-%m-%d')
                except Exception:
                    raise ValueError(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {date_str}ï¼Œæ”¯æŒYYYYMMDDæˆ–YYYY-MM-DD")
            
            # è§£æå¹¶éªŒè¯æ—¥æœŸèŒƒå›´
            try:
                start_dt = parse_simple_date(start_date)
                end_dt = parse_simple_date(end_date)
            except ValueError as e:
                logger.error(f"æ—¥æœŸè§£æå¤±è´¥: {str(e)}")
                return {'success': False, 'error': str(e)}
            
            if start_dt >= end_dt:
                logger.error(f"æ—¥æœŸèŒƒå›´æ— æ•ˆ: å¼€å§‹æ—¥æœŸ{start_date} >= ç»“æŸæ—¥æœŸ{end_date}")
                return {'success': False, 'error': 'å¼€å§‹æ—¥æœŸä¸èƒ½å¤§äºç­‰äºç»“æŸæ—¥æœŸ'}
            
            # é™åˆ¶æœ€å¤§å›æµ‹å‘¨æœŸ
            max_days = self.config.get('backtest', {}).get('max_period_days', 365*5)
            if (end_dt - start_dt).days > max_days:
                logger.warning(f"å›æµ‹å‘¨æœŸè¿‡é•¿ï¼ˆ{max_days}å¤©é™åˆ¶ï¼‰ï¼Œè‡ªåŠ¨æˆªæ–­ä¸ºæœ€è¿‘{max_days}å¤©")
                start_dt = end_dt - timedelta(days=max_days)
            
            # æ ¼å¼åŒ–ä¸ºYYYY-MM-DDï¼ˆé€‚é…æ•°æ®æºï¼‰
            start_date_str = start_dt.strftime('%Y-%m-%d')
            end_date_str = end_dt.strftime('%Y-%m-%d')
            
            # æ ¹æ®æ—¶é—´çº§åˆ«è·å–æ•°æ®
            if timeframe == 'weekly':
                df = self.data_api.get_weekly_data(symbol, start_date_str, end_date_str)
            elif timeframe == 'daily':
                df = self.data_api.get_daily_data(symbol, start_date_str, end_date_str)
            elif timeframe == 'minute':
                minute_days = self.config.get('data_fetcher', {}).get('minute_days', 30)
                df = self.data_api.get_minute_data(symbol, '5m', minute_days)
            else:
                return {'success': False, 'error': f'ä¸æ”¯æŒçš„æ—¶é—´çº§åˆ«: {timeframe}ï¼Œæ”¯æŒweekly/daily/minute'}
            
            # éªŒè¯æ•°æ®è´¨é‡
            if df.empty:
                logger.warning(f"è·å–çš„æ•°æ®ä¸ºç©º - ç¬¦å·: {symbol}, æ—¥æœŸèŒƒå›´: {start_date_str}è‡³{end_date_str}")
                return {'success': False, 'error': 'è·å–çš„æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æˆ–æ—¥æœŸèŒƒå›´'}
            
            if len(df) < 10:
                logger.warning(f"æ•°æ®ç‚¹æ•°ä¸è¶³: {len(df)}æ¡ï¼ˆè‡³å°‘éœ€è¦10ä¸ªæ•°æ®ç‚¹ï¼‰")
                return {'success': False, 'error': f'æ•°æ®ç‚¹æ•°ä¸è¶³ï¼Œä»…è·å–åˆ°{len(df)}æ¡ï¼Œè‡³å°‘éœ€è¦10ä¸ªæ•°æ®ç‚¹'}
            
            # æ£€æŸ¥å¿…è¦åˆ—
            required_columns = ['open', 'high', 'low', 'close', 'volume']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                logger.warning(f"ç¼ºå¤±å¿…è¦æ•°æ®åˆ—: {missing_columns}")
                return {'success': False, 'error': f'ç¼ºå¤±å¿…è¦æ•°æ®åˆ—: {missing_columns}ï¼Œå¿…é¡»åŒ…å«open/high/low/close/volume'}
            
            # å¤„ç†æ—¥æœŸåˆ—
            if 'date' not in df.columns:
                if 'timestamp' in df.columns:
                    df['date'] = pd.to_datetime(df['timestamp']).dt.date
                    df = df.rename(columns={'timestamp': 'datetime'})
                    logger.info("æ•°æ®åˆ—è½¬æ¢ï¼štimestamp -> datetimeï¼Œæ–°å¢dateåˆ—ï¼ˆæ—¥æœŸï¼‰")
                else:
                    logger.error("æ•°æ®ä¸­æ²¡æœ‰æ—¥æœŸåˆ—ï¼ˆdateï¼‰æˆ–æ—¶é—´æˆ³åˆ—ï¼ˆtimestampï¼‰")
                    return {'success': False, 'error': 'æ•°æ®ä¸­æ²¡æœ‰æ—¥æœŸåˆ—æˆ–æ—¶é—´æˆ³åˆ—ï¼Œæ— æ³•è¿›è¡Œå›æµ‹'}
            
            # æ•°æ®æ’åºå’Œå»é‡
            df = df.sort_values('date').drop_duplicates(subset=['date'], keep='last')
            df = df.reset_index(drop=True)
            
            logger.info(f"æ•°æ®é¢„å¤„ç†å®Œæˆ: {len(df)}æ¡æœ‰æ•ˆè®°å½•")
            return {'success': True, 'data': df}
            
        except DataFetchError as e:
            logger.error(f"æ•°æ®è·å–å¤±è´¥ï¼ˆæ•°æ®æºå¼‚å¸¸ï¼‰: {str(e)}")
            return {'success': False, 'error': f'æ•°æ®æºå¼‚å¸¸: {str(e)}'}
        except Exception as e:
            logger.error(f"æ•°æ®è·å–è¿‡ç¨‹å¼‚å¸¸: {str(e)}", exc_info=True)
            return {'success': False, 'error': str(e)}
    
    def _perform_chanlun_calculation(self, df: pd.DataFrame, timeframe: str) -> Dict[str, Any]:
        """æ‰§è¡Œç¼ è®ºè®¡ç®—ï¼ˆåŒ…å«åˆ†å‹ã€ç¬”ã€çº¿æ®µã€ä¸­æ¢è¯†åˆ«ï¼‰"""
        try:
            logger.info(f"å¼€å§‹ç¼ è®ºè®¡ç®— - æ—¶é—´çº§åˆ«: {timeframe}ï¼Œæ•°æ®é‡: {len(df)}æ¡")
            
            # æ ¹æ®æ—¶é—´çº§åˆ«åŠ è½½å¯¹åº”çš„ç¼ è®ºå‚æ•°
            chanlun_params = self.config.get('chanlun', {}).get(timeframe, {})
            if not chanlun_params:
                chanlun_params = self.config.get('chanlun', {}).get('default', {})
                logger.warning(f"æœªé…ç½®{timeframe}çº§åˆ«ç¼ è®ºå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°: {chanlun_params}")
            
            # æ‰§è¡Œç¼ è®ºè®¡ç®—
            result_df = self.calculator.calculate(
                df,
                timeframe=timeframe,
                fractal_sensitivity=chanlun_params.get('fractal_sensitivity', 3),
                pen_min_length=chanlun_params.get('pen_min_length', 5),
                segment_min_length=chanlun_params.get('segment_min_length', 3),
                central_bank_min_length=chanlun_params.get('central_bank_min_length', 5)
            )
            
            # éªŒè¯è®¡ç®—ç»“æœ
            required_calc_columns = ['top_fractal', 'bottom_fractal', 'pen_type', 'segment_type', 'central_bank']
            missing_calc_cols = [col for col in required_calc_columns if col not in result_df.columns]
            if missing_calc_cols:
                logger.warning(f"ç¼ è®ºè®¡ç®—ç¼ºå¤±éƒ¨åˆ†åˆ—: {missing_calc_cols}")
            
            logger.info("ç¼ è®ºè®¡ç®—å®Œæˆ")
            return {'success': True, 'data': result_df}
        except Exception as e:
            logger.error(f"ç¼ è®ºè®¡ç®—å¤±è´¥: {str(e)}", exc_info=True)
            return {'success': False, 'error': str(e)}
    
    def _execute_backtest(self, df: pd.DataFrame, initial_capital: float, timeframe: str) -> Dict[str, Any]:
        """æ‰§è¡Œå›æµ‹é€»è¾‘ï¼ˆåŸºäºç¼ è®ºä¿¡å·çš„äº¤æ˜“ç­–ç•¥ï¼‰"""
        try:
            logger.info(f"å¼€å§‹å›æµ‹æ‰§è¡Œ - åˆå§‹èµ„é‡‘: {initial_capital:.2f}ï¼Œæ—¶é—´çº§åˆ«: {timeframe}")
            
            # åˆå§‹åŒ–å›æµ‹å‚æ•°ï¼ˆå…¨éƒ¨ä½¿ç”¨getæ–¹æ³•ï¼Œé¿å…KeyErrorï¼‰
            backtest_config = self.config.get('backtest', {})
            backtest_params = {
                'initial_capital': initial_capital,
                'slippage': backtest_config.get('slippage', 0.001),  # æ»‘ç‚¹ç‡ 0.1%
                'transaction_cost': backtest_config.get('transaction_cost', 0.0003),  # äº¤æ˜“æˆæœ¬ 0.03%
                'max_position': backtest_config.get('max_single_position', 0.5),  # å•åªè‚¡ç¥¨æœ€å¤§ä»“ä½ 50%
                'stop_loss_ratio': backtest_config.get('stop_loss_ratio', 0.05),  # æ­¢æŸæ¯”ä¾‹ 5%
                'take_profit_ratio': backtest_config.get('take_profit_ratio', 0.1),  # æ­¢ç›ˆæ¯”ä¾‹ 10%
                'signal_type': backtest_config.get('signal_type', 'pen_segment_central_bank'),
                'min_holding_period': backtest_config.get('min_holding_period', 1)
            }
            
            # è°ƒç”¨è®¡ç®—å™¨çš„å›æµ‹æ–¹æ³•
            result = self.calculator.backtest(df, backtest_params, timeframe)
            
            # éªŒè¯å›æµ‹ç»“æœå®Œæ•´æ€§
            required_result_fields = [
                'equity_curve', 'drawdown', 'return_percent', 'max_drawdown',
                'sharpe_ratio', 'win_rate', 'total_trades', 'profit_factor',
                'volatility', 'downside_risk', 'sortino_ratio', 'calmar_ratio',
                'avg_holding_period', 'max_holding_period', 'monthly_trades',
                'trades', 'price_data'
            ]
            missing_fields = [field for field in required_result_fields if field not in result]
            if missing_fields:
                logger.warning(f"å›æµ‹ç»“æœç¼ºå¤±éƒ¨åˆ†å­—æ®µ: {missing_fields}")
                # è¡¥å……ç¼ºå¤±å­—æ®µçš„é»˜è®¤å€¼
                for field in missing_fields:
                    if field == 'equity_curve':
                        result[field] = pd.Series([initial_capital] * len(df), index=df.index)
                    elif field == 'drawdown':
                        result[field] = pd.Series([0.0] * len(df), index=df.index)
                    elif field.endswith('_percent'):
                        result[field] = 0.0
                    elif field.endswith('_ratio'):
                        result[field] = 0.0
                    elif field.endswith('_trades'):
                        result[field] = 0
                    elif field in ['trades', 'price_data']:
                        result[field] = pd.DataFrame() if field != 'trades' else []
            
            logger.info(
                f"å›æµ‹æ‰§è¡Œå®Œæˆ - æ€»äº¤æ˜“æ¬¡æ•°: {result.get('total_trades', 0)}, "
                f"æ€»å›æŠ¥: {result.get('return_percent', 0):.2f}%, "
                f"æœ€å¤§å›æ’¤: {result.get('max_drawdown', 0):.2f}%"
            )
            return {'success': True, 'data': result}
        except Exception as e:
            logger.error(f"å›æµ‹æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
            return {'success': False, 'error': str(e)}
    
    def _generate_comprehensive_report(self, result: Dict[str, Any], symbol: str, timeframe: str) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆå›æµ‹æŠ¥å‘Šï¼ˆåŒ…å«æ€§èƒ½ã€é£é™©ã€äº¤æ˜“æ´»åŠ¨åˆ†æï¼‰"""
        try:
            logger.info(f"ç”Ÿæˆç»¼åˆå›æµ‹æŠ¥å‘Š - è‚¡ç¥¨: {symbol}, æ—¶é—´çº§åˆ«: {timeframe}")
            
            # æå–æ ¸å¿ƒæŒ‡æ ‡
            performance = {
                'return_percent': round(result.get('return_percent', 0), 2),
                'max_drawdown': round(result.get('max_drawdown', 0), 2),
                'sharpe_ratio': round(result.get('sharpe_ratio', 0), 2),
                'win_rate': round(result.get('win_rate', 0) * 100, 2),
                'total_trades': result.get('total_trades', 0),
                'profit_factor': round(result.get('profit_factor', 0), 2),
                'expectancy': round(result.get('expectancy', 0), 2),
                'avg_profit_per_trade': round(result.get('avg_profit_per_trade', 0), 2),
                'avg_loss_per_trade': round(result.get('avg_loss_per_trade', 0), 2)
            }
            
            risk_metrics = {
                'volatility': round(result.get('volatility', 0) * 100, 2),
                'downside_risk': round(result.get('downside_risk', 0) * 100, 2),
                'sortino_ratio': round(result.get('sortino_ratio', 0), 2),
                'calmar_ratio': round(result.get('calmar_ratio', 0), 2),
                'value_at_risk': round(result.get('value_at_risk', 0), 2),
                'conditional_value_at_risk': round(result.get('conditional_value_at_risk', 0), 2)
            }
            
            trading_activity = {
                'avg_holding_period': round(result.get('avg_holding_period', 0), 1),
                'max_holding_period': result.get('max_holding_period', 0),
                'min_holding_period': result.get('min_holding_period', 0),
                'monthly_trades': result.get('monthly_trades', {}),
                'win_streak': result.get('win_streak', 0),
                'lose_streak': result.get('lose_streak', 0),
                'long_trades_count': result.get('long_trades_count', 0),
                'short_trades_count': result.get('short_trades_count', 0)
            }
            
            # ç”ŸæˆæŠ¥å‘Šä¸»ä½“
            report = {
                'metadata': {
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'start_date': result['actual_date_range'].get('start', 'N/A'),
                    'end_date': result['actual_date_range'].get('end', 'N/A'),
                    'initial_capital': result.get('initial_capital', 100000),
                    'final_capital': round(result.get('final_value', result.get('initial_capital', 100000)), 2),
                    'backtest_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                },
                'performance': performance,
                'risk_metrics': risk_metrics,
                'trading_activity': trading_activity,
                'strategy_params': self.config.get('backtest', {}),
                'chanlun_params': self.config.get('chanlun', {}).get(timeframe, self.config.get('chanlun', {}).get('default', {})),
                'summary': self._generate_report_summary(performance, risk_metrics)
            }
            
            # å¯¼å‡ºæŠ¥å‘Šï¼ˆå¦‚æœå¯ç”¨ï¼‰
            exporter_config = self.config.get('exporter', {})
            if exporter_config.get('enabled', False):
                export_formats = exporter_config.get('formats', ['json', 'csv'])
                export_path = self.exporter.export_report(
                    report, 
                    symbol=symbol, 
                    timeframe=timeframe,
                    formats=export_formats,
                    output_dir=exporter_config.get('output_dir', 'outputs/reports')
                )
                report['export_info'] = {
                    'path': export_path,
                    'formats': export_formats
                }
                logger.info(f"å›æµ‹æŠ¥å‘Šå·²å¯¼å‡ºè‡³: {export_path}")
            
            logger.info("ç»¼åˆå›æµ‹æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return report
        except Exception as e:
            logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
            return {'error': str(e), 'partial_report': {}}
    
    def _generate_report_summary(self, performance: Dict[str, Any], risk_metrics: Dict[str, Any]) -> str:
        """ç”ŸæˆæŠ¥å‘Šæ‘˜è¦ï¼ˆè‡ªç„¶è¯­è¨€æè¿°ï¼‰"""
        try:
            return_percent = performance['return_percent']
            max_drawdown = performance['max_drawdown']
            win_rate = performance['win_rate']
            total_trades = performance['total_trades']
            sharpe_ratio = performance['sharpe_ratio']
            
            summary_parts = []
            
            # æ”¶ç›Šæ€»ç»“
            if return_percent > 50:
                summary_parts.append(f"æ€»å›æŠ¥ç‡{return_percent}%ï¼Œè¡¨ç°ä¼˜ç§€")
            elif return_percent > 10:
                summary_parts.append(f"æ€»å›æŠ¥ç‡{return_percent}%ï¼Œè¡¨ç°è‰¯å¥½")
            elif return_percent > 0:
                summary_parts.append(f"æ€»å›æŠ¥ç‡{return_percent}%ï¼Œè¡¨ç°ä¸€èˆ¬")
            else:
                summary_parts.append(f"æ€»å›æŠ¥ç‡{return_percent}%ï¼Œè¡¨ç°ä¸ä½³")
            
            # é£é™©æ€»ç»“
            if max_drawdown < 10:
                summary_parts.append(f"æœ€å¤§å›æ’¤{max_drawdown}%ï¼Œé£é™©æ§åˆ¶ä¼˜ç§€")
            elif max_drawdown < 20:
                summary_parts.append(f"æœ€å¤§å›æ’¤{max_drawdown}%ï¼Œé£é™©æ§åˆ¶è‰¯å¥½")
            else:
                summary_parts.append(f"æœ€å¤§å›æ’¤{max_drawdown}%ï¼Œé£é™©è¾ƒé«˜")
            
            # äº¤æ˜“é¢‘ç‡æ€»ç»“
            if total_trades == 0:
                summary_parts.append("æœªäº§ç”Ÿä»»ä½•äº¤æ˜“")
            elif total_trades < 10:
                summary_parts.append(f"å…±æ‰§è¡Œ{total_trades}ç¬”äº¤æ˜“ï¼Œäº¤æ˜“é¢‘ç‡è¾ƒä½")
            elif total_trades < 50:
                summary_parts.append(f"å…±æ‰§è¡Œ{total_trades}ç¬”äº¤æ˜“ï¼Œäº¤æ˜“é¢‘ç‡é€‚ä¸­")
            else:
                summary_parts.append(f"å…±æ‰§è¡Œ{total_trades}ç¬”äº¤æ˜“ï¼Œäº¤æ˜“é¢‘ç‡è¾ƒé«˜")
            
            # èƒœç‡æ€»ç»“
            if win_rate > 60:
                summary_parts.append(f"èƒœç‡{win_rate}%ï¼Œç­–ç•¥å‡†ç¡®æ€§è¾ƒé«˜")
            elif win_rate > 50:
                summary_parts.append(f"èƒœç‡{win_rate}%ï¼Œç­–ç•¥å‡†ç¡®æ€§è‰¯å¥½")
            else:
                summary_parts.append(f"èƒœç‡{win_rate}%ï¼Œç­–ç•¥å‡†ç¡®æ€§ä¸€èˆ¬")
            
            # å¤æ™®æ¯”ç‡æ€»ç»“
            if sharpe_ratio > 2:
                summary_parts.append(f"å¤æ™®æ¯”ç‡{sharpe_ratio}ï¼Œé£é™©è°ƒæ•´åæ”¶ç›Šä¼˜ç§€")
            elif sharpe_ratio > 1:
                summary_parts.append(f"å¤æ™®æ¯”ç‡{sharpe_ratio}ï¼Œé£é™©è°ƒæ•´åæ”¶ç›Šè‰¯å¥½")
            else:
                summary_parts.append(f"å¤æ™®æ¯”ç‡{sharpe_ratio}ï¼Œé£é™©è°ƒæ•´åæ”¶ç›Šä¸€èˆ¬")
            
            return "ï¼Œ".join(summary_parts) + "ã€‚"
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šæ‘˜è¦å¤±è´¥: {str(e)}")
            return "æŠ¥å‘Šæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œè¯¦ç»†æ•°æ®è¯·æŸ¥çœ‹å®Œæ•´æŠ¥å‘Šã€‚"
    
    def _generate_detailed_charts(self, result: Dict[str, Any], symbol: str, timeframe: str) -> Dict[str, Any]:
        """ç”Ÿæˆè¯¦ç»†çš„å›æµ‹å›¾è¡¨ï¼ˆèµ„é‡‘æ›²çº¿ã€æœ€å¤§å›æ’¤ã€äº¤æ˜“ä¿¡å·ã€ç¼ è®ºç»“æ„ï¼‰"""
        try:
            logger.info(f"ç”Ÿæˆå›æµ‹å›¾è¡¨ - è‚¡ç¥¨: {symbol}, æ—¶é—´çº§åˆ«: {timeframe}")
            
            # åˆ›å»ºå›¾è¡¨ä¿å­˜ç›®å½•
            chart_config = self.config.get('plotter', {})
            base_chart_dir = chart_config.get('output_dir', 'outputs/charts')
            chart_dir = os.path.join(base_chart_dir, timeframe, symbol)
            os.makedirs(chart_dir, exist_ok=True)
            
            # 1. èµ„é‡‘æ›²çº¿å›¾è¡¨
            equity_curve_path = self.plotter.plot_equity_curve(
                equity_curve=result['equity_curve'],
                benchmark_curve=result.get('benchmark_curve'),
                save_path=os.path.join(chart_dir, f'{symbol}_equity_curve.png'),
                title=f'{symbol} {timeframe} èµ„é‡‘æ›²çº¿',
                xlabel='æ—¥æœŸ',
                ylabel='èµ„äº§ä»·å€¼ï¼ˆå…ƒï¼‰'
            )
            
            # 2. æœ€å¤§å›æ’¤å›¾è¡¨
            drawdown_path = self.plotter.plot_drawdown(
                drawdown=result['drawdown'],
                save_path=os.path.join(chart_dir, f'{symbol}_drawdown.png'),
                title=f'{symbol} {timeframe} æœ€å¤§å›æ’¤',
                xlabel='æ—¥æœŸ',
                ylabel='å›æ’¤æ¯”ä¾‹ï¼ˆ%ï¼‰'
            )
            
            # 3. äº¤æ˜“ä¿¡å·å›¾è¡¨ï¼ˆä»·æ ¼+ä¿¡å·+ä»“ä½ï¼‰
            signals_path = self.plotter.plot_signals(
                price_data=result['price_data'],
                trades=result['trades'],
                positions=result.get('positions'),
                save_path=os.path.join(chart_dir, f'{symbol}_trading_signals.png'),
                title=f'{symbol} {timeframe} äº¤æ˜“ä¿¡å·',
                xlabel='æ—¥æœŸ',
                ylabel='ä»·æ ¼ï¼ˆå…ƒï¼‰'
            )
            
            # 4. ç¼ è®ºç»“æ„å›¾è¡¨ï¼ˆKçº¿+åˆ†å‹+ç¬”+çº¿æ®µ+ä¸­æ¢ï¼‰
            chanlun_path = self.plotter.plot_chanlun_structure(
                price_data=result['price_data'],
                save_path=os.path.join(chart_dir, f'{symbol}_chanlun_structure.png'),
                title=f'{symbol} {timeframe} ç¼ è®ºç»“æ„',
                xlabel='æ—¥æœŸ',
                ylabel='ä»·æ ¼ï¼ˆå…ƒï¼‰'
            )
            
            # 5. æ€§èƒ½æŒ‡æ ‡é›·è¾¾å›¾
            radar_path = self.plotter.plot_performance_radar(
                performance=result['report']['performance'],
                risk_metrics=result['report']['risk_metrics'],
                save_path=os.path.join(chart_dir, f'{symbol}_performance_radar.png'),
                title=f'{symbol} {timeframe} æ€§èƒ½é›·è¾¾å›¾'
            )
            
            logger.info(f"å›æµ‹å›¾è¡¨ç”Ÿæˆå®Œæˆï¼Œä¿å­˜ç›®å½•: {chart_dir}")
            return {
                'success': True,
                'chart_dir': chart_dir,
                'equity_curve_path': equity_curve_path,
                'drawdown_path': drawdown_path,
                'signals_path': signals_path,
                'chanlun_structure_path': chanlun_path,
                'performance_radar_path': radar_path
            }
        except Exception as e:
            logger.error(f"å›¾è¡¨ç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
            return {'success': False, 'error': str(e), 'chart_dir': None}
    
    def _send_notifications(self, result: Dict[str, Any], symbol: str, timeframe: str) -> None:
        """å‘é€å›æµ‹ç»“æœé€šçŸ¥ï¼ˆé’‰é’‰ï¼‰"""
        try:
            logger.info(f"å‘é€å›æµ‹ç»“æœé€šçŸ¥ - è‚¡ç¥¨: {symbol}")
            
            # æå–æ ¸å¿ƒä¿¡æ¯
            return_percent = result.get('return_percent', 0)
            max_drawdown = result.get('max_drawdown', 0)
            total_trades = result.get('total_trades', 0)
            win_rate = result.get('win_rate', 0) * 100
            actual_date_range = result.get('actual_date_range', {})
            summary = result['report'].get('summary', '')
            
            # æ„å»ºé€šçŸ¥å†…å®¹
            content = (
                f"ğŸ“Š ç¼ è®ºå›æµ‹ç»“æœé€šçŸ¥\n"
                f"=======================\n"
                f"è‚¡ç¥¨ä»£ç : {symbol}\n"
                f"æ—¶é—´çº§åˆ«: {timeframe}\n"
                f"æ—¥æœŸèŒƒå›´: {actual_date_range.get('start', 'N/A')} è‡³ {actual_date_range.get('end', 'N/A')}\n"
                f"åˆå§‹èµ„é‡‘: {result.get('initial_capital', 100000):,.2f}å…ƒ\n"
                f"æœ€ç»ˆèµ„é‡‘: {result.get('final_value', result.get('initial_capital', 100000)):,.2f}å…ƒ\n"
                f"æ€»å›æŠ¥ç‡: {return_percent:.2f}%\n"
                f"æœ€å¤§å›æ’¤: {max_drawdown:.2f}%\n"
                f"äº¤æ˜“æ¬¡æ•°: {total_trades}æ¬¡\n"
                f"èƒœç‡: {win_rate:.2f}%\n"
                f"å¤æ™®æ¯”ç‡: {result.get('sharpe_ratio', 0):.2f}\n"
                f"=======================\n"
                f"ğŸ“ æ€»ç»“: {summary}\n"
                f"ğŸ“ è¯¦ç»†æŠ¥å‘Š: {result['report'].get('export_info', {}).get('path', 'æœªå¯¼å‡º')}"
            )
            
            # å‘é€æ–‡æœ¬é€šçŸ¥
            self.notifier.send_text(content)
            
            # å‘é€å›¾è¡¨ï¼ˆå¦‚æœç”ŸæˆæˆåŠŸï¼‰
            if result.get('charts', {}).get('success', False):
                chart_paths = [
                    result['charts']['equity_curve_path'],
                    result['charts']['signals_path'],
                    result['charts']['chanlun_structure_path']
                ]
                # è¿‡æ»¤ä¸å­˜åœ¨çš„å›¾è¡¨è·¯å¾„
                valid_chart_paths = [path for path in chart_paths if path and os.path.exists(path)]
                if valid_chart_paths:
                    self.notifier.send_images(valid_chart_paths)
                    logger.info(f"å·²å‘é€{len(valid_chart_paths)}å¼ å›¾è¡¨åˆ°é’‰é’‰")
            
            logger.info("å›æµ‹ç»“æœé€šçŸ¥å‘é€å®Œæˆ")
        except Exception as e:
            logger.error(f"é€šçŸ¥å‘é€å¤±è´¥: {str(e)}", exc_info=True)
    
    def _create_error_result(self, initial_capital: float, error_msg: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯ç»“æœå¯¹è±¡ï¼ˆç»Ÿä¸€é”™è¯¯è¿”å›æ ¼å¼ï¼‰"""
        return {
            'success': False,
            'error': error_msg,
            'initial_capital': initial_capital,
            'final_value': initial_capital,
            'return_percent': 0.0,
            'max_drawdown': 0.0,
            'sharpe_ratio': 0.0,
            'win_rate': 0.0,
            'total_trades': 0,
            'profit_factor': 0.0,
            'volatility': 0.0,
            'downside_risk': 0.0,
            'sortino_ratio': 0.0,
            'calmar_ratio': 0.0,
            'avg_holding_period': 0.0,
            'max_holding_period': 0,
            'monthly_trades': {},
            'trades': [],
            'price_data': pd.DataFrame(),
            'equity_curve': pd.Series(),
            'drawdown': pd.Series(),
            'actual_date_range': {},
            'report': {'error': error_msg, 'partial_report': {}},
            'charts': {'success': False, 'error': error_msg}
        }
    
    def batch_backtest(self, symbols: List[str], start_date: str, end_date: str, 
                      timeframe: str = 'weekly', initial_capital: float = 100000) -> Dict[str, Any]:
        """æ‰¹é‡å›æµ‹å¤šä¸ªè‚¡ç¥¨"""
        logger.info(f"å¼€å§‹æ‰¹é‡å›æµ‹ - æ ‡çš„æ•°é‡: {len(symbols)}, æ—¶é—´çº§åˆ«: {timeframe}, åˆå§‹èµ„é‡‘: {initial_capital:.2f}å…ƒ")
        
        # åˆå§‹åŒ–æ‰¹é‡å›æµ‹ç»“æœ
        batch_results = {
            'metadata': {
                'batch_id': datetime.now().strftime('%Y%m%d%H%M%S'),
                'start_date': start_date,
                'end_date': end_date,
                'timeframe': timeframe,
                'initial_capital_per_symbol': initial_capital,
                'total_symbols': len(symbols),
                'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'end_time': None
            },
            'success_count': 0,
            'fail_count': 0,
            'results': {},
            'summary': {
                'avg_return': 0.0,
                'median_return': 0.0,
                'max_return': -float('inf'),
                'min_return': float('inf'),
                'best_symbol': None,
                'worst_symbol': None,
                'avg_max_drawdown': 0.0,
                'avg_win_rate': 0.0,
                'avg_trades_count': 0.0,
                'profitable_symbols_count': 0,
                'profitable_ratio': 0.0
            }
        }
        
        # é€ä¸ªæ‰§è¡Œå›æµ‹
        for i, symbol in enumerate(symbols, 1):
            logger.info(f"\n===== æ‰¹é‡å›æµ‹è¿›åº¦: {i}/{len(symbols)} - è‚¡ç¥¨: {symbol} =====")
            try:
                # æ‰§è¡Œå•åªè‚¡ç¥¨å›æµ‹
                single_result = self.run_comprehensive_backtest(
                    symbol=symbol,
                    start_date=start_date,
                    end_date=end_date,
                    timeframe=timeframe,
                    initial_capital=initial_capital
                )
                
                batch_results['results'][symbol] = single_result
                
                # ç»Ÿè®¡æˆåŠŸ/å¤±è´¥
                if single_result.get('success', False):
                    batch_results['success_count'] += 1
                    
                    # æå–å…³é”®æŒ‡æ ‡ç”¨äºæ±‡æ€»
                    return_percent = single_result.get('return_percent', 0)
                    max_drawdown = single_result.get('max_drawdown', 0)
                    win_rate = single_result.get('win_rate', 0)
                    total_trades = single_result.get('total_trades', 0)
                    
                    # æ›´æ–°æ±‡æ€»ç»Ÿè®¡
                    batch_results['summary']['avg_return'] += return_percent
                    batch_results['summary']['avg_max_drawdown'] += max_drawdown
                    batch_results['summary']['avg_win_rate'] += win_rate
                    batch_results['summary']['avg_trades_count'] += total_trades
                    
                    # æ›´æ–°æœ€å€¼
                    if return_percent > batch_results['summary']['max_return']:
                        batch_results['summary']['max_return'] = return_percent
                        batch_results['summary']['best_symbol'] = symbol
                    if return_percent < batch_results['summary']['min_return']:
                        batch_results['summary']['min_return'] = return_percent
                        batch_results['summary']['worst_symbol'] = symbol
                    # ç»Ÿè®¡ç›ˆåˆ©æ ‡çš„
                    if return_percent > 0:
                        batch_results['summary']['profitable_symbols_count'] += 1
                else:
                    batch_results['fail_count'] += 1
                    logger.error(f"æ‰¹é‡å›æµ‹ {symbol} å¤±è´¥: {single_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            except Exception as e:
                logger.error(f"æ‰¹é‡å›æµ‹ {symbol} å¼‚å¸¸: {str(e)}", exc_info=True)
                batch_results['results'][symbol] = {
                    'success': False,
                    'error': str(e),
                    'initial_capital': initial_capital,
                    'final_value': initial_capital
                }
                batch_results['fail_count'] += 1
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        total_success = batch_results['success_count']
        if total_success > 0:
            batch_results['summary']['avg_return'] /= total_success
            batch_results['summary']['avg_max_drawdown'] /= total_success
            batch_results['summary']['avg_win_rate'] /= total_success
            batch_results['summary']['avg_trades_count'] /= total_success
            batch_results['summary']['profitable_ratio'] = (batch_results['summary']['profitable_symbols_count'] / total_success) * 100
        
        # è®¡ç®—ä¸­ä½æ•°å›æŠ¥
        return_list = [
            res.get('return_percent', 0) 
            for res in batch_results['results'].values() 
            if res.get('success', False)
        ]
        if return_list:
            batch_results['summary']['median_return'] = np.median(return_list)
        else:
            batch_results['summary']['median_return'] = 0.0
        
        # è¡¥å……ç»“æŸæ—¶é—´
        batch_results['metadata']['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # ä¿å­˜æ‰¹é‡å›æµ‹ç»“æœ
        batch_report_dir = self.config.get('exporter', {}).get('batch_report_dir', 'outputs/reports/batch')
        os.makedirs(batch_report_dir, exist_ok=True)
        batch_report_path = os.path.join(
            batch_report_dir,
            f'batch_backtest_{timeframe}_{batch_results["metadata"]["batch_id"]}.json'
        )
        with open(batch_report_path, 'w', encoding='utf-8') as f:
            json.dump(batch_results, f, ensure_ascii=False, indent=2)
        batch_results['report_path'] = batch_report_path
        
        # å‘é€æ‰¹é‡å›æµ‹æ‘˜è¦é€šçŸ¥
        if self.config.get('notifications', {}).get('enabled', False):
            self._send_batch_backtest_notification(batch_results)
        
        logger.info(
            f"\n===== æ‰¹é‡å›æµ‹å®Œæˆ =====\n"
            f"æ€»æ ‡çš„æ•°: {len(symbols)}\n"
            f"æˆåŠŸ: {batch_results['success_count']}ä¸ª\n"
            f"å¤±è´¥: {batch_results['fail_count']}ä¸ª\n"
            f"å¹³å‡å›æŠ¥ç‡: {batch_results['summary']['avg_return']:.2f}%\n"
            f"æœ€é«˜å›æŠ¥ç‡: {batch_results['summary']['max_return']:.2f}% ({batch_results['summary']['best_symbol']})\n"
            f"æœ€ä½å›æŠ¥ç‡: {batch_results['summary']['min_return']:.2f}% ({batch_results['summary']['worst_symbol']})\n"
            f"ç›ˆåˆ©æ ‡çš„æ¯”ä¾‹: {batch_results['summary']['profitable_ratio']:.2f}%\n"
            f"æŠ¥å‘Šä¿å­˜è·¯å¾„: {batch_report_path}"
        )
        
        return batch_results
    
    def _send_batch_backtest_notification(self, batch_results: Dict[str, Any]) -> None:
        """å‘é€æ‰¹é‡å›æµ‹æ‘˜è¦é€šçŸ¥"""
        try:
            summary = batch_results['summary']
            metadata = batch_results['metadata']
            
            content = (
                f"ğŸ“Š æ‰¹é‡ç¼ è®ºå›æµ‹å®Œæˆé€šçŸ¥\n"
                f"=======================\n"
                f"æ‰¹é‡ID: {metadata['batch_id']}\n"
                f"æ ‡çš„æ•°é‡: {metadata['total_symbols']}ä¸ª\n"
                f"æ—¶é—´çº§åˆ«: {metadata['timeframe']}\n"
                f"æ—¥æœŸèŒƒå›´: {metadata['start_date']} è‡³ {metadata['end_date']}\n"
                f"æ‰§è¡Œæ—¶é—´: {metadata['start_time']} - {metadata['end_time']}\n"
                f"=======================\n"
                f"âœ… æˆåŠŸ: {batch_results['success_count']}ä¸ª\n"
                f"âŒ å¤±è´¥: {batch_results['fail_count']}ä¸ª\n"
                f"ğŸ“ˆ å¹³å‡å›æŠ¥ç‡: {summary['avg_return']:.2f}%\n"
                f"ğŸ“Š ä¸­ä½æ•°å›æŠ¥ç‡: {summary['median_return']:.2f}%\n"
                f"ğŸ† æœ€ä½³æ ‡çš„: {summary['best_symbol']} ({summary['max_return']:.2f}%)\n"
                f"âš ï¸  æœ€å·®æ ‡çš„: {summary['worst_symbol']} ({summary['min_return']:.2f}%)\n"
                f"ğŸ’° ç›ˆåˆ©æ ‡çš„æ¯”ä¾‹: {summary['profitable_ratio']:.2f}%\n"
                f"ğŸ“Š å¹³å‡èƒœç‡: {summary['avg_win_rate']*100:.2f}%\n"
                f"=======================\n"
                f"ğŸ“ è¯¦ç»†æŠ¥å‘Š: {batch_results['report_path']}"
            )
            
            self.notifier.send_text(content)
            logger.info("æ‰¹é‡å›æµ‹æ‘˜è¦é€šçŸ¥å‘é€å®Œæˆ")
        except Exception as e:
            logger.error(f"æ‰¹é‡å›æµ‹é€šçŸ¥å‘é€å¤±è´¥: {str(e)}", exc_info=True)
    
    def optimize_parameters(self, symbol: str, start_date: str, end_date: str, 
                           param_ranges: Dict[str, List[Any]], timeframe: str = 'daily') -> Dict[str, Any]:
        """å‚æ•°ä¼˜åŒ–ï¼ˆç½‘æ ¼æœç´¢ï¼‰"""
        logger.info(f"å¼€å§‹å‚æ•°ä¼˜åŒ– - è‚¡ç¥¨: {symbol}, æ—¶é—´çº§åˆ«: {timeframe}")
        logger.info(f"å‚æ•°æœç´¢ç©ºé—´: {param_ranges}")
        
        from itertools import product
        import time
        
        # éªŒè¯è‚¡ç¥¨ä»£ç 
        self._validate_symbol_not_dataframe(symbol)
        
        # è·å–å¹¶éªŒè¯æ•°æ®ï¼ˆé¿å…é‡å¤è·å–ï¼‰
        data_result = self._acquire_and_validate_data(symbol, start_date, end_date, timeframe)
        if not data_result['success']:
            error_msg = f"å‚æ•°ä¼˜åŒ–å¤±è´¥: æ•°æ®è·å–å¤±è´¥ - {data_result['error']}"
            logger.error(error_msg)
            return {'success': False, 'error': error_msg}
        
        df = data_result['data']
        logger.info(f"å‚æ•°ä¼˜åŒ–æ•°æ®å‡†å¤‡å®Œæˆ: {len(df)}æ¡è®°å½•")
        
        # æ‰§è¡Œç¼ è®ºè®¡ç®—ï¼ˆåŸºç¡€è®¡ç®—ï¼Œå‚æ•°ä¼˜åŒ–æ—¶ä»…è°ƒæ•´ç­–ç•¥å‚æ•°ï¼‰
        calculation_result = self._perform_chanlun_calculation(df, timeframe)
        if not calculation_result['success']:
            error_msg = f"å‚æ•°ä¼˜åŒ–å¤±è´¥: ç¼ è®ºè®¡ç®—å¤±è´¥ - {calculation_result['error']}"
            logger.error(error_msg)
            return {'success': False, 'error': error_msg}
        
        calculated_df = calculation_result['data']
        
        # ç”Ÿæˆå‚æ•°ç»„åˆï¼ˆç½‘æ ¼æœç´¢ï¼‰
        param_names = list(param_ranges.keys())
        param_combinations = product(*param_ranges.values())
        total_combinations = np.prod([len(range_list) for range_list in param_ranges.values()])
        logger.info(f"å‚æ•°ç»„åˆæ€»æ•°: {total_combinations}ä¸ª")
        
        # åˆå§‹åŒ–ä¼˜åŒ–ç»“æœ
        best_result = None
        best_params = None
        best_score = -float('inf')
        optimization_results = []
        score_metric = self.config.get('optimization', {}).get('score_metric', 'sharpe_ratio')
        
        # éå†æ‰€æœ‰å‚æ•°ç»„åˆ
        for i, params in enumerate(param_combinations, 1):
            param_dict = dict(zip(param_names, params))
            logger.info(f"æµ‹è¯•å‚æ•°ç»„åˆ {i}/{total_combinations}: {param_dict}")
            
            try:
                start_time = time.time()
                
                # ä¸´æ—¶ä¿®æ”¹å›æµ‹å‚æ•°
                backtest_config = self.config.get('backtest', {}).copy()
                backtest_config.update(param_dict)
                
                # æ‰§è¡Œå›æµ‹
                backtest_result = self._execute_backtest(
                    calculated_df,
                    initial_capital=self.config.get('optimization', {}).get('initial_capital', 100000),
                    timeframe=timeframe
                )
                
                if not backtest_result['success']:
                    logger.warning(f"å‚æ•°ç»„åˆ {param_dict} å›æµ‹å¤±è´¥: {backtest_result['error']}")
                    continue
                
                result = backtest_result['data']
                result['parameters'] = param_dict
                result['test_duration'] = round(time.time() - start_time, 2)
                
                # è®¡ç®—è¯„åˆ†ï¼ˆæ ¹æ®ç›®æ ‡æŒ‡æ ‡ï¼‰
                if score_metric == 'sharpe_ratio':
                    score = result.get('sharpe_ratio', 0)
                elif score_metric == 'return_percent':
                    score = result.get('return_percent', 0) / max(result.get('max_drawdown', 1), 0.01)
                elif score_metric == 'profit_factor':
                    score = result.get('profit_factor', 0)
                elif score_metric == 'win_rate':
                    score = result.get('win_rate', 0)
                else:
                    score = result.get('sharpe_ratio', 0)
                
                result['score'] = score
                optimization_results.append(result)
                
                # æ›´æ–°æœ€ä½³ç»“æœ
                if score > best_score:
                    best_score = score
                    best_result = result
                    best_params = param_dict
                    logger.info(f"æ›´æ–°æœ€ä½³å‚æ•°: {best_params}, æœ€ä½³è¯„åˆ†: {best_score:.2f}")
            
            except Exception as e:
                logger.error(f"å‚æ•°ç»„åˆ {param_dict} æµ‹è¯•å¤±è´¥: {str(e)}", exc_info=True)
                continue
        
        # éªŒè¯ä¼˜åŒ–ç»“æœ
        if best_result is None:
            error_msg = "æ‰€æœ‰å‚æ•°ç»„åˆæµ‹è¯•å¤±è´¥ï¼Œæœªæ‰¾åˆ°æœ‰æ•ˆå‚æ•°"
            logger.error(error_msg)
            return {'success': False, 'error': error_msg}
        
        # ä¿å­˜ä¼˜åŒ–ç»“æœ
        opt_config = self.config.get('optimization', {})
        opt_output_dir = opt_config.get('output_dir', 'outputs/optimization')
        os.makedirs(opt_output_dir, exist_ok=True)
        
        opt_result_path = os.path.join(
            opt_output_dir,
            f'{symbol}_{timeframe}_param_optimization_{datetime.now().strftime("%Y%m%d%H%M%S")}.json'
        )
        
        with open(opt_result_path, 'w', encoding='utf-8') as f:
            json.dump({
                'metadata': {
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'start_date': start_date,
                    'end_date': end_date,
                    'score_metric': score_metric,
                    'total_combinations': total_combinations,
                    'success_combinations': len(optimization_results),
                    'optimization_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                },
                'best_parameters': best_params,
                'best_result': best_result,
                'all_results': optimization_results,
                'param_ranges': param_ranges
            }, f, ensure_ascii=False, indent=2)
        
        # å‘é€ä¼˜åŒ–ç»“æœé€šçŸ¥
        if self.config.get('notifications', {}).get('enabled', False):
            self._send_parameter_optimization_notification(best_params, best_result, symbol, timeframe)
        
        logger.info(
            f"å‚æ•°ä¼˜åŒ–å®Œæˆ - æœ€ä½³å‚æ•°: {best_params}\n"
            f"æœ€ä½³è¯„åˆ†: {best_score:.2f} ({score_metric})\n"
            f"å›æµ‹å›æŠ¥ç‡: {best_result.get('return_percent', 0):.2f}%\n"
            f"æœ€å¤§å›æ’¤: {best_result.get('max_drawdown', 0):.2f}%\n"
            f"ç»“æœä¿å­˜è·¯å¾„: {opt_result_path}"
        )
        
        return {
            'success': True,
            'best_parameters': best_params,
            'best_result': best_result,
            'best_score': best_score,
            'all_results': optimization_results,
            'optimization_path': opt_result_path,
            'metadata': {
                'symbol': symbol,
                'timeframe': timeframe,
                'score_metric': score_metric,
                'total_combinations': total_combinations
            }
        }
    
    def _send_parameter_optimization_notification(self, best_params: Dict[str, Any], 
                                                best_result: Dict[str, Any], symbol: str, timeframe: str) -> None:
        """å‘é€å‚æ•°ä¼˜åŒ–ç»“æœé€šçŸ¥"""
        try:
            content = (
                f"ğŸ”§ ç¼ è®ºå‚æ•°ä¼˜åŒ–å®Œæˆé€šçŸ¥\n"
                f"=======================\n"
                f"è‚¡ç¥¨ä»£ç : {symbol}\n"
                f"æ—¶é—´çº§åˆ«: {timeframe}\n"
                f"ä¼˜åŒ–ç›®æ ‡: {self.config.get('optimization', {}).get('score_metric', 'sharpe_ratio')}\n"
                f"=======================\n"
                f"ğŸ† æœ€ä½³å‚æ•°:\n"
            )
            # æ ¼å¼åŒ–å‚æ•°è¾“å‡º
            for param_name, param_value in best_params.items():
                content += f"  â€¢ {param_name}: {param_value}\n"
            
            content += (
                f"=======================\n"
                f"ğŸ“Š å›æµ‹æ€§èƒ½:\n"
                f"  â€¢ æ€»å›æŠ¥ç‡: {best_result.get('return_percent', 0):.2f}%\n"
                f"  â€¢ æœ€å¤§å›æ’¤: {best_result.get('max_drawdown', 0):.2f}%\n"
                f"  â€¢ å¤æ™®æ¯”ç‡: {best_result.get('sharpe_ratio', 0):.2f}\n"
                f"  â€¢ èƒœç‡: {best_result.get('win_rate', 0)*100:.2f}%\n"
                f"  â€¢ äº¤æ˜“æ¬¡æ•°: {best_result.get('total_trades', 0)}æ¬¡\n"
                f"=======================\n"
                f"ğŸ“ è¯¦ç»†ç»“æœ: {self.config.get('optimization', {}).get('output_dir', 'outputs/optimization')}"
            )
            
            self.notifier.send_text(content)
            logger.info("å‚æ•°ä¼˜åŒ–ç»“æœé€šçŸ¥å‘é€å®Œæˆ")
        except Exception as e:
            logger.error(f"å‚æ•°ä¼˜åŒ–é€šçŸ¥å‘é€å¤±è´¥: {str(e)}", exc_info=True)

class ChanlunBacktester:
    """ç¼ è®ºå›æµ‹å™¨å¤–å±‚åŒ…è£…ç±»ï¼ˆæä¾›ç»Ÿä¸€è°ƒç”¨æ¥å£ï¼‰"""
    
    def __init__(self, config_path: str = 'config/system.yaml'):
        """åˆå§‹åŒ–ç¼ è®ºå›æµ‹å™¨"""
        self.config = load_config(config_path)
        self.engine = BacktestEngine(self.config)
        logger.info("ChanlunBacktester åˆå§‹åŒ–å®Œæˆ")
    
    def run(self, symbol: str, start_date: str, end_date: str, timeframe: str = 'weekly', 
           initial_capital: float = 100000) -> Dict[str, Any]:
        """è¿è¡Œå•åªè‚¡ç¥¨å›æµ‹"""
        self.engine._validate_symbol_not_dataframe(symbol)
        return self.engine.run_comprehensive_backtest(symbol, start_date, end_date, timeframe, initial_capital)
    
    def run_batch(self, symbols: List[str], start_date: str, end_date: str, timeframe: str = 'weekly', 
                 initial_capital: float = 100000) -> Dict[str, Any]:
        """è¿è¡Œæ‰¹é‡å›æµ‹"""
        return self.engine.batch_backtest(symbols, start_date, end_date, timeframe, initial_capital)
    
    def optimize_params(self, symbol: str, start_date: str, end_date: str, param_ranges: Dict[str, List[Any]], 
                       timeframe: str = 'daily') -> Dict[str, Any]:
        """è¿è¡Œå‚æ•°ä¼˜åŒ–"""
        return self.engine.optimize_parameters(symbol, start_date, end_date, param_ranges, timeframe)

def main():
    """å‘½ä»¤è¡Œå…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç¼ è®ºå›æµ‹ç³»ç»Ÿ - å‘½ä»¤è¡Œå·¥å…·')
    
    # åŸºç¡€å‚æ•°
    parser.add_argument('-c', '--config', default='config/system.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-m', '--mode', required=True, choices=['single', 'batch', 'optimize'], help='è¿è¡Œæ¨¡å¼ï¼šsingle(å•åª)/batch(æ‰¹é‡)/optimize(å‚æ•°ä¼˜åŒ–)')
    parser.add_argument('-s', '--symbol', help='è‚¡ç¥¨ä»£ç ï¼ˆsingle/optimizeæ¨¡å¼å¿…å¡«ï¼‰')
    parser.add_argument('-S', '--symbols', nargs='+', help='è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆbatchæ¨¡å¼å¿…å¡«ï¼‰')
    parser.add_argument('-t', '--timeframe', default='daily', choices=['weekly', 'daily', 'minute'], help='æ—¶é—´çº§åˆ«')
    parser.add_argument('--start_date', required=True, help='å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæˆ–YYYY-MM-DDï¼‰')
    parser.add_argument('--end_date', required=True, help='ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæˆ–YYYY-MM-DDï¼‰')
    parser.add_argument('--capital', type=float, default=100000, help='åˆå§‹èµ„é‡‘')
    
    # å‚æ•°ä¼˜åŒ–ç›¸å…³å‚æ•°
    parser.add_argument('--param_ranges', type=str, help='å‚æ•°èŒƒå›´JSONå­—ç¬¦ä¸²ï¼ˆoptimizeæ¨¡å¼å¿…å¡«ï¼‰')
    parser.add_argument('--score_metric', default='sharpe_ratio', choices=['sharpe_ratio', 'return_percent', 'profit_factor', 'win_rate'], help='ä¼˜åŒ–ç›®æ ‡æŒ‡æ ‡')
    
    # è¾“å‡ºç›¸å…³å‚æ•°
    parser.add_argument('--output_dir', default='outputs', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--enable_notify', action='store_true', help='å¯ç”¨é’‰é’‰é€šçŸ¥')
    parser.add_argument('--enable_plot', action='store_true', help='å¯ç”¨å›¾è¡¨ç”Ÿæˆ')
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼ï¼ˆè¾“å‡ºè¯¦ç»†æ—¥å¿—ï¼‰')
    
    args = parser.parse_args()
    
    # è°ƒè¯•æ¨¡å¼é…ç½®
    if args.debug:
        logger.setLevel(logging.DEBUG)
        for handler in logger.handlers:
            handler.setLevel(logging.DEBUG)
        logger.debug("è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
    
    # åˆå§‹åŒ–å›æµ‹å™¨
    try:
        backtester = ChanlunBacktester(args.config)
    except Exception as e:
        logger.critical(f"å›æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        sys.exit(1)
    
    # è°ƒæ•´é…ç½®ï¼ˆä½¿ç”¨setdefaulté¿å…KeyErrorï¼‰
    # åˆå§‹åŒ–notificationsé…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if 'notifications' not in backtester.config:
        backtester.config['notifications'] = {}
    backtester.config['notifications']['enabled'] = args.enable_notify
    
    # åˆå§‹åŒ–plotteré…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if 'plotter' not in backtester.config:
        backtester.config['plotter'] = {}
    backtester.config['plotter']['enabled'] = args.enable_plot
    
    # åˆå§‹åŒ–exporteré…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if 'exporter' not in backtester.config:
        backtester.config['exporter'] = {}
    backtester.config['exporter']['output_dir'] = args.output_dir
    
    # åˆå§‹åŒ–optimizationé…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if args.mode == 'optimize' and 'optimization' not in backtester.config:
        backtester.config['optimization'] = {}
    if args.mode == 'optimize':
        backtester.config['optimization']['score_metric'] = args.score_metric
    
    # æ ¹æ®æ¨¡å¼æ‰§è¡Œ
    try:
        if args.mode == 'single':
            # å•åªè‚¡ç¥¨å›æµ‹
            if not args.symbol:
                logger.error("singleæ¨¡å¼å¿…é¡»æŒ‡å®š--symbolå‚æ•°")
                sys.exit(1)
            
            result = backtester.run(
                symbol=args.symbol,
                start_date=args.start_date,
                end_date=args.end_date,
                timeframe=args.timeframe,
                initial_capital=args.capital
            )
            
            # è¾“å‡ºç»“æœæ‘˜è¦
            if result.get('success', False):
                logger.info("\n" + "="*50)
                logger.info("å•åªè‚¡ç¥¨å›æµ‹ç»“æœæ‘˜è¦")
                logger.info("="*50)
                logger.info(f"è‚¡ç¥¨ä»£ç : {args.symbol}")
                logger.info(f"æ€»å›æŠ¥ç‡: {result.get('return_percent', 0):.2f}%")
                logger.info(f"æœ€å¤§å›æ’¤: {result.get('max_drawdown', 0):.2f}%")
                logger.info(f"äº¤æ˜“æ¬¡æ•°: {result.get('total_trades', 0)}æ¬¡")
                logger.info(f"èƒœç‡: {result.get('win_rate', 0)*100:.2f}%")
                logger.info(f"å¤æ™®æ¯”ç‡: {result.get('sharpe_ratio', 0):.2f}")
                logger.info(f"æŠ¥å‘Šè·¯å¾„: {result['report'].get('export_info', {}).get('path', 'æœªå¯¼å‡º')}")
                logger.info(f"å›¾è¡¨è·¯å¾„: {result['charts'].get('chart_dir', 'æœªç”Ÿæˆ')}")
                logger.info("="*50)
            else:
                logger.error(f"å›æµ‹å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                sys.exit(1)
        
        elif args.mode == 'batch':
            # æ‰¹é‡å›æµ‹
            if not args.symbols:
                logger.error("batchæ¨¡å¼å¿…é¡»æŒ‡å®š--symbolså‚æ•°")
                sys.exit(1)
            
            result = backtester.run_batch(
                symbols=args.symbols,
                start_date=args.start_date,
                end_date=args.end_date,
                timeframe=args.timeframe,
                initial_capital=args.capital
            )
            
            # è¾“å‡ºæ‰¹é‡ç»“æœæ‘˜è¦
            logger.info("\n" + "="*50)
            logger.info("æ‰¹é‡å›æµ‹ç»“æœæ‘˜è¦")
            logger.info("="*50)
            logger.info(f"æ€»æ ‡çš„æ•°: {len(args.symbols)}")
            logger.info(f"æˆåŠŸ: {result['success_count']}ä¸ª")
            logger.info(f"å¤±è´¥: {result['fail_count']}ä¸ª")
            logger.info(f"å¹³å‡å›æŠ¥ç‡: {result['summary']['avg_return']:.2f}%")
            logger.info(f"æœ€ä½³æ ‡çš„: {result['summary']['best_symbol']} ({result['summary']['max_return']:.2f}%)")
            logger.info(f"æœ€å·®æ ‡çš„: {result['summary']['worst_symbol']} ({result['summary']['min_return']:.2f}%)")
            logger.info(f"ç›ˆåˆ©æ ‡çš„æ¯”ä¾‹: {result['summary']['profitable_ratio']:.2f}%")
            logger.info(f"æ‰¹é‡æŠ¥å‘Šè·¯å¾„: {result['report_path']}")
            logger.info("="*50)
        
        elif args.mode == 'optimize':
            # å‚æ•°ä¼˜åŒ–
            if not args.symbol:
                logger.error("optimizeæ¨¡å¼å¿…é¡»æŒ‡å®š--symbolå‚æ•°")
                sys.exit(1)
            if not args.param_ranges:
                logger.error("optimizeæ¨¡å¼å¿…é¡»æŒ‡å®š--param_rangeså‚æ•°ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰")
                sys.exit(1)
            
            # è§£æå‚æ•°èŒƒå›´
            try:
                param_ranges = json.loads(args.param_ranges)
            except json.JSONDecodeError as e:
                logger.error(f"param_rangesè§£æå¤±è´¥: {str(e)}")
                sys.exit(1)
            
            result = backtester.optimize_params(
                symbol=args.symbol,
                start_date=args.start_date,
                end_date=args.end_date,
                param_ranges=param_ranges,
                timeframe=args.timeframe
            )
            
            # è¾“å‡ºä¼˜åŒ–ç»“æœæ‘˜è¦
            if result.get('success', False):
                logger.info("\n" + "="*50)
                logger.info("å‚æ•°ä¼˜åŒ–ç»“æœæ‘˜è¦")
                logger.info("="*50)
                logger.info(f"è‚¡ç¥¨ä»£ç : {args.symbol}")
                logger.info(f"ä¼˜åŒ–ç›®æ ‡: {args.score_metric}")
                logger.info(f"æœ€ä½³å‚æ•°: {result['best_parameters']}")
                logger.info(f"æœ€ä½³è¯„åˆ†: {result['best_score']:.2f}")
                logger.info(f"å›æµ‹å›æŠ¥ç‡: {result['best_result'].get('return_percent', 0):.2f}%")
                logger.info(f"æœ€å¤§å›æ’¤: {result['best_result'].get('max_drawdown', 0):.2f}%")
                logger.info(f"ä¼˜åŒ–ç»“æœè·¯å¾„: {result['optimization_path']}")
                logger.info("="*50)
            else:
                logger.error(f"å‚æ•°ä¼˜åŒ–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                sys.exit(1)
        
        logger.info("ç¨‹åºæ‰§è¡Œå®Œæˆ")
        sys.exit(0)
        
    except Exception as e:
        logger.critical(f"ç¨‹åºæ‰§è¡Œå¼‚å¸¸: {str(e)}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()