#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
512690å®Œæ•´åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨
æ•´åˆMACDèƒŒé©°åˆ†æã€ä¹°å–ä¿¡å·åˆ†æå’Œç¼ è®ºéªŒè¯ç»“æœï¼Œç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
"""

import os
import json
import datetime
import pandas as pd
import argparse
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger('512690ReportGenerator')

class ReportGenerator:
    """
    åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨ç±»
    è´Ÿè´£æ•´åˆå„ç§åˆ†æç»“æœå¹¶ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    """
    
    def __init__(self, symbol="512690", results_dir="./results", data_dir="./data"):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            symbol (str): è‚¡ç¥¨ä»£ç 
            results_dir (str): åˆ†æç»“æœå­˜å‚¨ç›®å½•
            data_dir (str): åŸå§‹æ•°æ®å­˜å‚¨ç›®å½•
        """
        self.symbol = symbol
        self.results_dir = results_dir
        self.data_dir = data_dir
        self.report_time = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        self.report_file = f"{results_dir}/{symbol}_comprehensive_report_{self.report_time}.txt"
        
        # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
        os.makedirs(results_dir, exist_ok=True)
        
        # å­˜å‚¨å„åˆ†æç»“æœ
        self.macd_results = None
        self.signal_results = None
        self.chanlun_results = None
        self.latest_price = None
        
    def load_macd_results(self):
        """åŠ è½½MACDèƒŒé©°åˆ†æç»“æœ"""
        try:
            # æŸ¥æ‰¾æœ€æ–°çš„MACDåˆ†æç»“æœæ–‡ä»¶
            macd_files = [f for f in os.listdir(self.results_dir) 
                         if f.startswith(f"{self.symbol}_macd_divergence_results") and f.endswith(".json")]
            if macd_files:
                latest_file = sorted(macd_files)[-1]  # è·å–æœ€æ–°çš„æ–‡ä»¶
                file_path = os.path.join(self.results_dir, latest_file)
                with open(file_path, 'r', encoding='utf-8') as f:
                    self.macd_results = json.load(f)
                logger.info(f"å·²åŠ è½½MACDèƒŒé©°åˆ†æç»“æœ: {latest_file}")
            else:
                logger.warning("æœªæ‰¾åˆ°MACDèƒŒé©°åˆ†æç»“æœæ–‡ä»¶")
        except Exception as e:
            logger.error(f"åŠ è½½MACDèƒŒé©°åˆ†æç»“æœå¤±è´¥: {str(e)}")
    
    def load_signal_results(self):
        """åŠ è½½ä¹°å–ä¿¡å·åˆ†æç»“æœ"""
        try:
            # æŸ¥æ‰¾æœ€æ–°çš„ä¿¡å·åˆ†æç»“æœæ–‡ä»¶
            signal_files = [f for f in os.listdir(self.results_dir) 
                          if f.startswith(f"{self.symbol}_signals_") and f.endswith(".json")]
            if signal_files:
                latest_file = sorted(signal_files)[-1]  # è·å–æœ€æ–°çš„æ–‡ä»¶
                file_path = os.path.join(self.results_dir, latest_file)
                with open(file_path, 'r', encoding='utf-8') as f:
                    self.signal_results = json.load(f)
                logger.info(f"å·²åŠ è½½ä¹°å–ä¿¡å·åˆ†æç»“æœ: {latest_file}")
            else:
                logger.warning("æœªæ‰¾åˆ°ä¹°å–ä¿¡å·åˆ†æç»“æœæ–‡ä»¶")
        except Exception as e:
            logger.error(f"åŠ è½½ä¹°å–ä¿¡å·åˆ†æç»“æœå¤±è´¥: {str(e)}")
    
    def load_chanlun_results(self):
        """åŠ è½½ç¼ è®ºéªŒè¯ç»“æœ"""
        try:
            # æŸ¥æ‰¾æœ€æ–°çš„ç¼ è®ºéªŒè¯ç»“æœæ–‡ä»¶
            chanlun_files = [f for f in os.listdir(self.results_dir) 
                            if f.startswith(f"{self.symbol}_chanlun_verification") and f.endswith(".txt")]
            if chanlun_files:
                latest_file = sorted(chanlun_files)[-1]  # è·å–æœ€æ–°çš„æ–‡ä»¶
                self.chanlun_results = latest_file
                logger.info(f"å·²æ‰¾åˆ°ç¼ è®ºéªŒè¯æŠ¥å‘Š: {latest_file}")
        except Exception as e:
            logger.error(f"åŠ è½½ç¼ è®ºéªŒè¯ç»“æœå¤±è´¥: {str(e)}")
    
    def load_latest_price(self):
        """åŠ è½½æœ€æ–°ä»·æ ¼æ•°æ®"""
        try:
            daily_data_path = os.path.join(self.data_dir, "daily", f"{self.symbol}_daily.csv")
            if os.path.exists(daily_data_path):
                df = pd.read_csv(daily_data_path)
                if not df.empty:
                    # å‡è®¾æ—¥æœŸåˆ—æ˜¯ç¬¬ä¸€åˆ—ï¼Œæ”¶ç›˜ä»·åˆ—æ˜¯'close'æˆ–ç±»ä¼¼åç§°
                    # æ ¹æ®å®é™…CSVæ ¼å¼è°ƒæ•´
                    date_columns = [col for col in df.columns if 'date' in col.lower()]
                    if not date_columns:
                        date_columns = [df.columns[0]]  # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯æ—¥æœŸ
                    
                    close_columns = [col for col in df.columns if 'close' in col.lower()]
                    if not close_columns:
                        close_columns = [df.columns[4]]  # å‡è®¾ç¬¬5åˆ—æ˜¯æ”¶ç›˜ä»·
                    
                    df = df.sort_values(by=date_columns[0], ascending=False)
                    self.latest_price = df.iloc[0][close_columns[0]]
                    logger.info(f"å·²åŠ è½½æœ€æ–°ä»·æ ¼: {self.latest_price}")
        except Exception as e:
            logger.error(f"åŠ è½½æœ€æ–°ä»·æ ¼å¤±è´¥: {str(e)}")
    
    def generate_report(self):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        try:
            # åŠ è½½æ‰€æœ‰åˆ†æç»“æœ
            self.load_macd_results()
            self.load_signal_results()
            self.load_chanlun_results()
            self.load_latest_price()
            
            # ç”ŸæˆæŠ¥å‘Š
            with open(self.report_file, 'w', encoding='utf-8') as f:
                # æŠ¥å‘Šæ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
                f.write("=" * 80 + "\n")
                f.write(f"{self.symbol} ç»¼åˆåˆ†ææŠ¥å‘Š\n")
                f.write("=" * 80 + "\n\n")
                f.write(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                if self.latest_price:
                    f.write(f"æœ€æ–°ä»·æ ¼: {self.latest_price}\n\n")
                
                # MACDèƒŒé©°åˆ†ææ‘˜è¦
                f.write("\n" + "-" * 80 + "\n")
                f.write("1. MACDèƒŒé©°åˆ†ææ‘˜è¦\n")
                f.write("-" * 80 + "\n")
                if self.macd_results:
                    # æ›´çµæ´»åœ°å¤„ç†MACDç»“æœç»“æ„
                    bottom_divergences = self.macd_results.get("bottom_divergences", [])
                    top_divergences = self.macd_results.get("top_divergences", [])
                    current_trend = self.macd_results.get("current_trend", {})
                    
                    f.write(f"åº•èƒŒé©°ä¿¡å·æ•°é‡: {len(bottom_divergences)}\n")
                    f.write(f"é¡¶èƒŒé©°ä¿¡å·æ•°é‡: {len(top_divergences)}\n")
                    
                    # æ˜¾ç¤ºæœ€æ–°çš„èƒŒé©°ä¿¡å·ï¼ˆæ·»åŠ é”™è¯¯å¤„ç†ï¼‰
                    if bottom_divergences:
                        try:
                            # å°è¯•ä½¿ç”¨ä¸åŒçš„æ—¥æœŸé”®å
                            for date_key in ["end_date", "date", "time", "datetime"]:
                                if all(date_key in item for item in bottom_divergences):
                                    latest_bottom = sorted(bottom_divergences, key=lambda x: x[date_key], reverse=True)[0]
                                    break
                            else:
                                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¥æœŸé”®ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå…ƒç´ 
                                latest_bottom = bottom_divergences[0]
                            
                            f.write(f"\næœ€æ–°åº•èƒŒé©°ä¿¡å·:\n")
                            f.write(f"  å¼ºåº¦: {latest_bottom.get('strength', 0):.2f}/100\n")
                            
                            # å°è¯•è·å–æ—¥æœŸä¿¡æ¯
                            start_date = latest_bottom.get('start_date', latest_bottom.get('date', ''))
                            end_date = latest_bottom.get('end_date', latest_bottom.get('date', ''))
                            if start_date and end_date and start_date != end_date:
                                f.write(f"  æœŸé—´: {start_date} è‡³ {end_date}\n")
                            else:
                                f.write(f"  æ—¥æœŸ: {start_date or end_date}\n")
                            
                            f.write(f"  æè¿°: {latest_bottom.get('description', '')}\n")
                        except Exception:
                            f.write("  æ— æ³•è§£æåº•èƒŒé©°ä¿¡å·è¯¦ç»†ä¿¡æ¯\n")
                    
                    if top_divergences:
                        try:
                            # å°è¯•ä½¿ç”¨ä¸åŒçš„æ—¥æœŸé”®å
                            for date_key in ["end_date", "date", "time", "datetime"]:
                                if all(date_key in item for item in top_divergences):
                                    latest_top = sorted(top_divergences, key=lambda x: x[date_key], reverse=True)[0]
                                    break
                            else:
                                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¥æœŸé”®ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå…ƒç´ 
                                latest_top = top_divergences[0]
                            
                            f.write(f"\næœ€æ–°é¡¶èƒŒé©°ä¿¡å·:\n")
                            f.write(f"  å¼ºåº¦: {latest_top.get('strength', 0):.2f}/100\n")
                            
                            # å°è¯•è·å–æ—¥æœŸä¿¡æ¯
                            start_date = latest_top.get('start_date', latest_top.get('date', ''))
                            end_date = latest_top.get('end_date', latest_top.get('date', ''))
                            if start_date and end_date and start_date != end_date:
                                f.write(f"  æœŸé—´: {start_date} è‡³ {end_date}\n")
                            else:
                                f.write(f"  æ—¥æœŸ: {start_date or end_date}\n")
                            
                            f.write(f"  æè¿°: {latest_top.get('description', '')}\n")
                        except Exception:
                            f.write("  æ— æ³•è§£æé¡¶èƒŒé©°ä¿¡å·è¯¦ç»†ä¿¡æ¯\n")
                    
                    # å½“å‰MACDè¶‹åŠ¿
                    f.write(f"\nå½“å‰MACDè¶‹åŠ¿:\n")
                    f.write(f"  æ–¹å‘: {'å‘ä¸Š' if current_trend.get('direction', 'down') == 'up' else 'å‘ä¸‹'}\n")
                    f.write(f"  MACDæŸ±å€¼: {current_trend.get('histogram_value', 0):.6f}\n")
                    f.write(f"  è¶‹åŠ¿å¼ºåº¦: {current_trend.get('strength', 'å¼±')}\n")
                    f.write(f"  æ“ä½œå»ºè®®: {current_trend.get('suggestion', 'è§‚æœ›')}\n")
                else:
                    f.write("  æœªæ‰¾åˆ°MACDèƒŒé©°åˆ†æç»“æœ\n")
                
                # ä¹°å–ä¿¡å·åˆ†ææ‘˜è¦
                f.write("\n" + "-" * 80 + "\n")
                f.write("2. ä¹°å–ä¿¡å·åˆ†ææ‘˜è¦\n")
                f.write("-" * 80 + "\n")
                if self.signal_results:
                    try:
                        # çµæ´»å¤„ç†ä¿¡å·æ•°æ®ç»“æ„ - å¯èƒ½æ˜¯åˆ—è¡¨æˆ–å­—å…¸
                        if isinstance(self.signal_results, dict):
                            signals = self.signal_results.get("signals", [])
                        elif isinstance(self.signal_results, list):
                            signals = self.signal_results
                        else:
                            signals = []
                        
                        # è¿‡æ»¤æœ‰æ•ˆçš„ä¿¡å·ï¼ˆå…·æœ‰å¿…è¦å­—æ®µï¼‰
                        valid_signals = []
                        for s in signals:
                            if isinstance(s, dict) and 'type' in s:
                                valid_signals.append(s)
                        
                        if not valid_signals:
                            f.write("  æœªæ‰¾åˆ°æœ‰æ•ˆçš„ä¿¡å·æ•°æ®\n")
                        else:
                            buy_signals = [s for s in valid_signals if s.get("type", "").lower() == "buy"]
                            sell_signals = [s for s in valid_signals if s.get("type", "").lower() == "sell"]
                            
                            f.write(f"ä¿¡å·æ€»æ•°: {len(valid_signals)}\n")
                            f.write(f"ä¹°å…¥ä¿¡å·: {len(buy_signals)}\n")
                            f.write(f"å–å‡ºä¿¡å·: {len(sell_signals)}\n")
                            
                            # æ˜¾ç¤ºæœ€è¿‘çš„å‡ ä¸ªä¿¡å·ï¼ˆå¦‚æœæœ‰æ—¥æœŸå­—æ®µï¼‰
                            try:
                                # æ‰¾å‡ºå«æœ‰æ—¥æœŸä¿¡æ¯çš„ä¿¡å·å¹¶æ’åº
                                dated_signals = [s for s in valid_signals if any(k in s for k in ['date', 'time', 'datetime'])]
                                for date_key in ['date', 'time', 'datetime']:
                                    if any(date_key in s for s in dated_signals):
                                        recent_signals = sorted(dated_signals, key=lambda x: x.get(date_key, ''), reverse=True)[:5]
                                        break
                                else:
                                    # å¦‚æœæ²¡æœ‰æ—¥æœŸä¿¡æ¯ï¼Œåªæ˜¾ç¤ºå‰5ä¸ª
                                    recent_signals = valid_signals[:5]
                                
                                f.write(f"\næœ€è¿‘5ä¸ªä¿¡å·:\n")
                                for signal in recent_signals:
                                    # è·å–æ—¥æœŸä¿¡æ¯
                                    date = signal.get('date', signal.get('time', signal.get('datetime', '')))
                                    signal_type = signal.get('type', 'æœªçŸ¥')
                                    description = signal.get('description', '')
                                    f.write(f"  {date} - {signal_type} - {description}\n")
                                
                                # æ˜¾ç¤ºæœ€è¿‘ä¿¡å·ç±»å‹
                                if recent_signals:
                                    latest_signal = recent_signals[0]
                                    latest_date = latest_signal.get('date', latest_signal.get('time', latest_signal.get('datetime', '')))
                                    latest_type = latest_signal.get('type', 'æœªçŸ¥')
                                    latest_desc = latest_signal.get('description', '')
                                    f.write(f"\næœ€æ–°ä¿¡å·: {latest_date} - {latest_type}\n")
                                    f.write(f"ä¿¡å·æè¿°: {latest_desc}\n")
                            except Exception:
                                f.write("  æ— æ³•æ˜¾ç¤ºæœ€è¿‘ä¿¡å·è¯¦æƒ…\n")
                    except Exception as e:
                        logger.error(f"å¤„ç†ä¹°å–ä¿¡å·æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                        f.write("  å¤„ç†ä¿¡å·æ•°æ®æ—¶å‡ºé”™\n")
                else:
                    f.write("  æœªæ‰¾åˆ°ä¹°å–ä¿¡å·åˆ†æç»“æœ\n")
                
                # ç¼ è®ºåˆ†ææ‘˜è¦
                f.write("\n" + "-" * 80 + "\n")
                f.write("3. ç¼ è®ºåˆ†ææ‘˜è¦\n")
                f.write("-" * 80 + "\n")
                if self.chanlun_results:
                    f.write(f"ç¼ è®ºéªŒè¯æŠ¥å‘Š: {self.chanlun_results}\n")
                    # å°è¯•ä»ç¼ è®ºéªŒè¯æŠ¥å‘Šä¸­æå–å…³é”®ä¿¡æ¯
                    chanlun_report_path = os.path.join(self.results_dir, self.chanlun_results)
                    try:
                        with open(chanlun_report_path, 'r', encoding='utf-8') as cf:
                            chanlun_content = cf.read()
                            
                            # æå–åˆ†å‹æ•°é‡
                            if "åˆ†å‹æ•°é‡" in chanlun_content:
                                for line in chanlun_content.split('\n'):
                                    if "åˆ†å‹æ•°é‡" in line:
                                        f.write(f"  {line.strip()}\n")
                                        break
                            
                            # æå–ç¬”åˆ’åˆ†ä¿¡æ¯
                            if "ç¬”æ€»æ•°" in chanlun_content:
                                for line in chanlun_content.split('\n'):
                                    if "ç¬”æ€»æ•°" in line:
                                        f.write(f"  {line.strip()}\n")
                                        break
                            
                            # æå–æœ€è¿‘çš„ç¬”åˆ’åˆ†
                            if "æœ€è¿‘çš„ç¬”åˆ’åˆ†" in chanlun_content:
                                f.write("  æœ€è¿‘çš„ç¬”åˆ’åˆ†ä¿¡æ¯:\n")
                                capture = False
                                count = 0
                                for line in chanlun_content.split('\n'):
                                    if "æœ€è¿‘çš„ç¬”åˆ’åˆ†" in line:
                                        capture = True
                                    elif capture and count < 5:  # åªæå–å‰å‡ è¡Œæœ‰ç”¨ä¿¡æ¯
                                        if line.strip():  # å¿½ç•¥ç©ºè¡Œ
                                            f.write(f"    {line.strip()}\n")
                                            count += 1
                                    elif capture and count >= 5:
                                        break
                        
                    except Exception as e:
                        logger.error(f"è¯»å–ç¼ è®ºéªŒè¯æŠ¥å‘Šå¤±è´¥: {str(e)}")
                else:
                    f.write("  æœªæ‰¾åˆ°ç¼ è®ºéªŒè¯ç»“æœ\n")
                
                # ç»¼åˆç»“è®ºå’Œå»ºè®®
                f.write("\n" + "-" * 80 + "\n")
                f.write("4. ç»¼åˆç»“è®ºä¸æŠ•èµ„å»ºè®®\n")
                f.write("-" * 80 + "\n")
                
                # åŸºäºå„åˆ†æç»“æœç”Ÿæˆç»¼åˆå»ºè®®
                recommendations = []
                
                # MACDå»ºè®®
                if self.macd_results and "current_trend" in self.macd_results:
                    macd_suggestion = self.macd_results["current_trend"].get("suggestion", "")
                    if macd_suggestion:
                        recommendations.append(f"MACDåˆ†æå»ºè®®: {macd_suggestion}")
                
                # ä¿¡å·å»ºè®®
                if self.signal_results and "signals" in self.signal_results and self.signal_results["signals"]:
                    latest_signal = sorted(self.signal_results["signals"], key=lambda x: x["date"], reverse=True)[0]
                    recommendations.append(f"æœ€è¿‘ä¿¡å·({latest_signal['date']}): {latest_signal['type']} - {latest_signal['description']}")
                
                # ç¼ è®ºå»ºè®®
                # ä»ç¼ è®ºæŠ¥å‘Šä¸­æå–å»ºè®®
                if self.chanlun_results:
                    chanlun_report_path = os.path.join(self.results_dir, self.chanlun_results)
                    try:
                        with open(chanlun_report_path, 'r', encoding='utf-8') as cf:
                            chanlun_content = cf.read()
                            if "äº¤æ˜“å»ºè®®" in chanlun_content:
                                for line in chanlun_content.split('\n'):
                                    if "äº¤æ˜“å»ºè®®" in line or "æ³¨æ„é£é™©" in line:
                                        recommendations.append(f"ç¼ è®ºå»ºè®®: {line.strip().replace('ğŸ“‰', '').replace('ğŸ¯ äº¤æ˜“å»ºè®®:', '').strip()}")
                    except Exception:
                        pass
                
                # å†™å…¥å»ºè®®
                if recommendations:
                    for rec in recommendations:
                        f.write(f"{rec}\n")
                else:
                    f.write("æ ¹æ®ç°æœ‰åˆ†ææ•°æ®ä¸è¶³ï¼Œå»ºè®®ç»“åˆæ›´å¤šæŒ‡æ ‡è¿›è¡Œåˆ¤æ–­\n")
                
                # ç»¼åˆé£é™©æç¤º
                f.write("\n" + "-" * 80 + "\n")
                f.write("5. é£é™©æç¤º\n")
                f.write("-" * 80 + "\n")
                f.write("1. æœ¬æŠ¥å‘ŠåŸºäºå†å²æ•°æ®å’ŒæŠ€æœ¯åˆ†æï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®\n")
                f.write("2. å¸‚åœºå­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œå®é™…èµ°åŠ¿å¯èƒ½ä¸åˆ†æç»“æœä¸ç¬¦\n")
                f.write("3. æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…\n")
                f.write("4. è¯·ç»“åˆä¸ªäººé£é™©åå¥½å’Œèµ„é‡‘çŠ¶å†µåšå‡ºæŠ•èµ„å†³ç­–\n")
                
            logger.info(f"ç»¼åˆåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {self.report_file}")
            return self.report_file
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Šå¤±è´¥: {str(e)}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="ç”ŸæˆETFç»¼åˆåˆ†ææŠ¥å‘Š")
    parser.add_argument("--symbol", type=str, default="512690", help="ETFä»£ç ï¼Œé»˜è®¤512690")
    parser.add_argument("--results-dir", type=str, default="./results", help="åˆ†æç»“æœå­˜å‚¨ç›®å½•")
    parser.add_argument("--data-dir", type=str, default="./data", help="åŸå§‹æ•°æ®å­˜å‚¨ç›®å½•")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    generator = ReportGenerator(
        symbol=args.symbol,
        results_dir=args.results_dir,
        data_dir=args.data_dir
    )
    
    # ç”ŸæˆæŠ¥å‘Š
    report_file = generator.generate_report()
    print(f"ç»¼åˆåˆ†ææŠ¥å‘Šå·²æˆåŠŸç”Ÿæˆ: {report_file}")

if __name__ == "__main__":
    main()